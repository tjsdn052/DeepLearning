{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d852a0e-6ee9-4735-be04-ce8eaea24ebd",
   "metadata": {},
   "source": [
    "2020136098 이선우 HW2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89786783-af1d-4cd1-ad9d-c1f2e1cb0bce",
   "metadata": {},
   "source": [
    "# **titanic_dataset.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4d62645-d149-4bd1-b3ed-8a44db63baa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "class TitanicDataset(Dataset):\n",
    "  def __init__(self, X, y): #X는 특징, Y는 타겟\n",
    "    self.X = torch.FloatTensor(X) # 입력 데이터를 float tensor로\n",
    "    self.y = torch.LongTensor(y)  # 타겟 데이터를 long tensor로\n",
    "\n",
    "  def __len__(self): # 데이터셋 길이 반환\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx): # 해당 인덱스 특징, 타겟 반환\n",
    "    feature = self.X[idx]\n",
    "    target = self.y[idx]\n",
    "    return {'input': feature, 'target': target}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}, Target Shape: {2}\".format(\n",
    "      len(self.X), self.X.shape, self.y.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4204b313-a2f8-484c-b334-7141e1dbb45e",
   "metadata": {},
   "source": [
    "Titanic 데이터셋을 관리한다. \n",
    "특징(feature)와 타겟(target) 값을 저장하고 데이터 셋의 길이 확인, 인덱스로 특징, 타겟 값을 반환하며 데이터셋의 크기와 형태를 확인할 수 있다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fd427371-c126-420e-af2c-6ffb78ee760f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicTestDataset(Dataset):\n",
    "  def __init__(self, X): # float tensor로 변환\n",
    "    self.X = torch.FloatTensor(X)\n",
    "\n",
    "  def __len__(self): # 데이터셋 길이 반환\n",
    "    return len(self.X)\n",
    "\n",
    "  def __getitem__(self, idx): # 해당 입력 데이터 반환\n",
    "    feature = self.X[idx]\n",
    "    return {'input': feature}\n",
    "\n",
    "  def __str__(self):\n",
    "    str = \"Data Size: {0}, Input Shape: {1}\".format(\n",
    "      len(self.X), self.X.shape\n",
    "    )\n",
    "    return str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794db4c6-641d-4da5-b57c-acf6e95d28df",
   "metadata": {},
   "source": [
    "Titanic Test 데이터셋을 관리한다. 검증 데이터셋이므로 특징만 FloatTensor로 변환해 저장하며 데이터 셋의 길이 확인, 인덱스로 특징 값을 반환하며 데이터셋의 크기와 형태를 확인할 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "18b1d959-21b9-4239-bb02-096c211c6688",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset():\n",
    "    #팡일 경로 설정\n",
    "    CURRENT_FILE_PATH = os.getcwd()\n",
    "    train_data_path = os.path.join(CURRENT_FILE_PATH, \"train.csv\")\n",
    "    test_data_path = os.path.join(CURRENT_FILE_PATH, \"test.csv\")\n",
    "\n",
    "    # csv 파일 불러오고 저장\n",
    "    train_df = pd.read_csv(train_data_path)\n",
    "    test_df = pd.read_csv(test_data_path)\n",
    "\n",
    "    # 훈련, 테스트 데이터 결합 후 전처리 함수 적용\n",
    "    all_df = pd.concat([train_df, test_df], sort=False)\n",
    "    all_df = get_preprocessed_dataset_1(all_df)\n",
    "    all_df = get_preprocessed_dataset_2(all_df)\n",
    "    all_df = get_preprocessed_dataset_3(all_df)\n",
    "    all_df = get_preprocessed_dataset_4(all_df)\n",
    "    all_df = get_preprocessed_dataset_5(all_df)\n",
    "    all_df = get_preprocessed_dataset_6(all_df)\n",
    "\n",
    "    # 위 과정 거친 후 데이터셋을 훈련, 검증용으로 분할\n",
    "    train_X = all_df[~all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "    train_y = train_df[\"Survived\"]\n",
    "    test_X = all_df[all_df[\"Survived\"].isnull()].drop(\"Survived\", axis=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "    dataset = TitanicDataset(train_X.values, train_y.values)\n",
    "    #print(dataset)\n",
    "    # 데이터셋 전체를 비율에 따라 분할, 훈련 - 80%, 검증 - 20%\n",
    "    train_dataset, validation_dataset = random_split(dataset, [0.8, 0.2])\n",
    "    # 데스트 데이터셋 생성, 타깃 없음\n",
    "    test_dataset = TitanicTestDataset(test_X.values)\n",
    "    #print(test_dataset)\n",
    "\n",
    "    return train_dataset, validation_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d726d6-d75d-45f3-8726-27e5a8be18da",
   "metadata": {},
   "source": [
    "데이터 전처리 후 학습, 검증, 테스트 데이터셋을 반환하는 함수이다. train.csv, test.csv 파일을 불러온 후 하나의 데이터프레임으로 합친다. 합친 데이터를 get_preprocessed_dataset_1 ... get_preprocessed_dataset_6의 전처리 과정을 거치고 훈련 / 검증 데이터로 분할한다. <br><br>\n",
    "train_X => 결측치가 없는 샘플들 중에서 생존 여부 정보를 제외한 훈련용 특징 데이터<br>\n",
    "train_y => 타깃(target) 훈련 데이터의 생존 여부 데이터\n",
    "test_X => 테스트 데이터의 특징 데이터<br><br>\n",
    "데이터셋 전체를 비율에 따라 분할하며 train_dataset - 80%, validation_dataset - 20% 테스트 데이터셋을 생성한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "10bb883d-1fb8-4e24-89c9-65268c8f9a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_1(all_df): # 전처리 함수 - Fare 결측치 처리\n",
    "    # Pclass별 Fare 평균값을 사용하여 Fare 결측치 메우기\n",
    "    Fare_mean = all_df[[\"Pclass\", \"Fare\"]].groupby(\"Pclass\").mean().reset_index()\n",
    "    Fare_mean.columns = [\"Pclass\", \"Fare_mean\"]\n",
    "    all_df = pd.merge(all_df, Fare_mean, on=\"Pclass\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Fare\"].isnull()), \"Fare\"] = all_df[\"Fare_mean\"]\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f7f42f-5909-4b6b-9be2-a70f9892d273",
   "metadata": {},
   "source": [
    "Fare 결측치를 처리한다. Pclass별로 승객의 Fare 평균 계산한 후 Fare값이 결측치이면 Pclass에 따른 평균 Fare로 값을 채운다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "94690190-e952-40fc-a21b-c3b90d590ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_2(all_df): # 전처리 함수 - Name 분리(family_name, honorific, name)\n",
    "    # name을 세 개의 컬럼으로 분리하여 다시 all_df에 합침\n",
    "    name_df = all_df[\"Name\"].str.split(\"[,.]\", n=2, expand=True)\n",
    "    name_df.columns = [\"family_name\", \"honorific\", \"name\"]\n",
    "    name_df[\"family_name\"] = name_df[\"family_name\"].str.strip()\n",
    "    name_df[\"honorific\"] = name_df[\"honorific\"].str.strip()\n",
    "    name_df[\"name\"] = name_df[\"name\"].str.strip()\n",
    "    # 원본 데이터프레임에 추가\n",
    "    all_df = pd.concat([all_df, name_df], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bed260b-3811-4338-9bf1-074ef42557a1",
   "metadata": {},
   "source": [
    "Name을 분리한다. 이름 컬럼을 ,. 기준으로 family_name, honorific, name로 문자열을 나누고 공백을 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8f3850e9-cd75-4b1e-ac7b-16852e95b1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_3(all_df): # 전처리 함수 - Age 결측치 처리\n",
    "    # honorific별 Age 평균값을 사용하여 Age 결측치 메우기\n",
    "    honorific_age_mean = all_df[[\"honorific\", \"Age\"]].groupby(\"honorific\").median().round().reset_index()\n",
    "    honorific_age_mean.columns = [\"honorific\", \"honorific_age_mean\", ]\n",
    "    all_df = pd.merge(all_df, honorific_age_mean, on=\"honorific\", how=\"left\")\n",
    "    all_df.loc[(all_df[\"Age\"].isnull()), \"Age\"] = all_df[\"honorific_age_mean\"]\n",
    "    # honorific_age_mean 컬럼 제거\n",
    "    all_df = all_df.drop([\"honorific_age_mean\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7376faea-5b09-405c-928d-2403fd3d27af",
   "metadata": {},
   "source": [
    "Age 결측치를 처리한다. honorific별로 Age의 평균값을 구해 결측치가 있는 Age 값을 채운다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1273bd34-ed70-4fdb-94b2-3d76a1fd63f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_4(all_df): # 전처리 함수 - 가족 수 계산 및 불필요한 컬럼 삭제\n",
    "    # 가족수(family_num) 컬럼 새롭게 추가\n",
    "    all_df[\"family_num\"] = all_df[\"Parch\"] + all_df[\"SibSp\"]\n",
    "\n",
    "    # 혼자탑승(alone) 컬럼 새롭게 추가\n",
    "    all_df.loc[all_df[\"family_num\"] == 0, \"alone\"] = 1\n",
    "    all_df[\"alone\"].fillna(0, inplace=True)\n",
    "\n",
    "    # 학습에 불필요한 컬럼 제거\n",
    "    all_df = all_df.drop([\"PassengerId\", \"Name\", \"family_name\", \"name\", \"Ticket\", \"Cabin\"], axis=1)\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72493ecc-e09e-4039-b029-0328149468cc",
   "metadata": {},
   "source": [
    "가족 수 계산 및 불필요한 컬럼을 제거한다. Parch와 SibSp을 더해 가족 수를 계한하는 컬럼을 추가하고 가족 수가 0인 승객은 alone 컬럼을 추가하며 결측치도 처리한다. 학습에 이용되지 않는 컬럼은 제거한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e934a8c-5177-47f8-bbb9-4280aa6928a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_5(all_df): # 전처리 함수 - honorific 값 단순화\n",
    "    # honorific 값 개수 줄이기\n",
    "    all_df.loc[\n",
    "    ~(\n",
    "            (all_df[\"honorific\"] == \"Mr\") |\n",
    "            (all_df[\"honorific\"] == \"Miss\") |\n",
    "            (all_df[\"honorific\"] == \"Mrs\") |\n",
    "            (all_df[\"honorific\"] == \"Master\")\n",
    "    ),\n",
    "    \"honorific\"\n",
    "    ] = \"other\"\n",
    "    # Embarked 결측치를 \"missing\"으로 채움\n",
    "    all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n",
    "\n",
    "    return all_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e84b49f-651d-40cd-9067-61c164a3e25e",
   "metadata": {},
   "source": [
    "honorific 값을 단순화한다. honorific 값이 Mr, Miss, Mrs, Master에 속하지 않는 승객들의 honorific 값을 other로 합친다. Embarked 컬럼의 결측치는 missing으로 채운다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "248ab566-2e5b-4986-a0bf-e00397152ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_preprocessed_dataset_6(all_df): # 전처리 함수 - 카테고리형 변수 수치형로 변환\n",
    "    # 카테고리 변수를 LabelEncoder를 사용하여 수치값으로 변경하기\n",
    "    category_features = all_df.columns[all_df.dtypes == \"object\"]\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    for category_feature in category_features:\n",
    "        le = LabelEncoder()\n",
    "        if all_df[category_feature].dtypes == \"object\":\n",
    "          le = le.fit(all_df[category_feature])\n",
    "          all_df[category_feature] = le.transform(all_df[category_feature])\n",
    "\n",
    "    return all_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e838f6-9ff0-457f-8751-7133605677a1",
   "metadata": {},
   "source": [
    "카테고리형 변수를 수치값으로 변경한다. object 타입인 칼럼을 ategory_features에 담아 LabelEncoder를 이용하여 수치값으로 변경한다. ex) \"C\", \"Q\", \"S\" -> 0, 1, 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4a001f2-e122-4a4f-86db-89ecce76980d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class MyModel(nn.Module):\n",
    "  def __init__(self, n_input, n_output):\n",
    "    super().__init__()\n",
    "    # ReLU 사용\n",
    "    self.model = nn.Sequential(\n",
    "      nn.Linear(n_input, 30),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(30, 30),\n",
    "      nn.ReLU(),\n",
    "      nn.Linear(30, n_output),\n",
    "    )\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.model(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e95f145-0bdd-42a9-a875-8e964456e7b6",
   "metadata": {},
   "source": [
    "클래스 MyModel => PyTorch의 nn.Module 클래스 상속받은 클래스<br>\n",
    "첫 번째 Fully Connected Layer => 특성 수만큼의 데이터를 받아 30개의 출력값을 생성<br>\n",
    "활성화 함수 ReLU 이용 입력이 0보다 크면 그대로 반환하고, 0 이하인 경우 0을 반환<br>\n",
    "두 번째 Fully Connected Layer => 30개의 입력을 받아 30개의 출력값을 생성<br>\n",
    "다시 ReLU를 사용하여 비선형성 추가<br>\n",
    "마지막 출력층 =>  30개의 입력을 받아 출력 차원(n_output)만큼의 값을 생성 (생존할 확률과 사망할 확률 각각 출력)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d884587f-2ec1-44e3-93e6-b8ac95e7d2c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2ed6172f-9015-402a-8365-f7b18043f90f",
   "metadata": {},
   "source": [
    "순전파 함수 forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "45a3fdf0-d4b4-4d3f-b7d7-7421e3cc12dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 테스트 함수\n",
    "def test(test_data_loader):\n",
    "  print(\"[TEST]\")\n",
    "  # test_data_loader에서 첫 번째 배치 가져옴\n",
    "  batch = next(iter(test_data_loader))\n",
    "  print(\"{0}\".format(batch['input'].shape))\n",
    "  # 모델 객체 생성 (11개 특징 입력, 출력 차원은 2 / 생존여부(0,1))\n",
    "  my_model = MyModel(n_input=11, n_output=2)\n",
    "  # 배치의 입력 데이터 받고 예측 수행\n",
    "  output_batch = my_model(batch['input'])\n",
    "  # 높은 값 반환\n",
    "  prediction_batch = torch.argmax(output_batch, dim=1)\n",
    "  for idx, prediction in enumerate(prediction_batch, start=892):\n",
    "      print(idx, prediction.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19381512-3ea5-49f3-9ca4-4a106e27297e",
   "metadata": {},
   "source": [
    "테스트 데이터를 이용하여 모델이 예측한 결과 출력<br>\n",
    "test_data_loader에서 첫 번째 배치 가져오고 모델 객체 생성 (11개 특징 입력, 출력 차원은 2 / 생존여부(0,1))<br>\n",
    "batch['input'] 데이터를 모델에 입력하여 예측,  각 승객에 대해 두 개의 출력 값을 반환 ex) [0.2, 0.8] => 생존할 확률이 80% 사망할 확률이 20%<br>\n",
    "예측 결과 중 가장 높은 값을 가지는 인덱스를 반환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b9d7fe15-16cc-4f11-9562-43e5670a386e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이선우\\AppData\\Local\\Temp\\ipykernel_10876\\4144865856.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\이선우\\AppData\\Local\\Temp\\ipykernel_10876\\4050156303.py:13: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset: 713, validation_dataset.shape: 178, test_dataset: 418\n",
      "################################################## 1\n",
      "0 - tensor([ 1.0000,  0.0000, 52.0000,  1.0000,  1.0000, 93.5000,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "1 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "2 - tensor([ 1.0000,  0.0000, 22.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "3 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "4 - tensor([ 3.0000,  0.0000, 26.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "5 - tensor([ 3.0000,  0.0000, 15.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "6 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "7 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000, 20.2125,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "8 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "9 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "10 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "11 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 38.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "12 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "13 - tensor([  1.0000,   0.0000,  18.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "14 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 35.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "15 - tensor([ 3.0000,  0.0000,  1.0000,  0.0000,  2.0000, 15.7417,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "16 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "17 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "18 - tensor([ 1.0000,  1.0000, 19.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "19 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  1.0000, 61.9792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "20 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7375,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "21 - tensor([ 3.0000,  0.0000,  4.0000,  1.0000,  1.0000, 16.7000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "22 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "23 - tensor([ 1.0000,  1.0000, 38.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "24 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "25 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "26 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "27 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.6292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "28 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "29 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "30 - tensor([ 2.0000,  1.0000, 48.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "31 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "32 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "33 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "34 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "35 - tensor([  1.0000,   0.0000,  21.0000,   2.0000,   2.0000, 262.3750,   0.0000,\n",
      "         87.5090,   1.0000,   4.0000,   0.0000]): 1\n",
      "36 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  1.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "37 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "38 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "39 - tensor([ 1.0000,  1.0000, 60.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "40 - tensor([ 2.0000,  0.0000, 41.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "41 - tensor([  1.0000,   0.0000,  30.0000,   0.0000,   0.0000, 106.4250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "42 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "43 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "44 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "45 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "46 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "47 - tensor([  1.0000,   0.0000,  31.0000,   0.0000,   2.0000, 164.8667,   2.0000,\n",
      "         87.5090,   1.0000,   2.0000,   0.0000]): 1\n",
      "48 - tensor([ 2.0000,  0.0000, 17.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "49 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "50 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "51 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "52 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.7125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "53 - tensor([ 3.0000,  1.0000,  1.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "54 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "55 - tensor([ 3.0000,  0.0000,  9.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "56 - tensor([ 3.0000,  1.0000, 26.0000,  2.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "57 - tensor([ 3.0000,  0.0000, 22.0000,  2.0000,  0.0000, 23.2500,  1.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "58 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "59 - tensor([ 1.0000,  1.0000, 49.0000,  0.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "60 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "61 - tensor([  1.0000,   0.0000,  38.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "62 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "63 - tensor([ 2.0000,  1.0000, 21.0000,  1.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "64 - tensor([  1.0000,   0.0000,  43.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "65 - tensor([  1.0000,   0.0000,  35.0000,   0.0000,   0.0000, 135.6333,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "66 - tensor([ 3.0000,  0.0000,  8.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "67 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "68 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "69 - tensor([ 2.0000,  0.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "70 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "71 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "72 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 42.4000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "73 - tensor([ 2.0000,  0.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "74 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "75 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "76 - tensor([ 3.0000,  1.0000,  3.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "77 - tensor([ 3.0000,  0.0000, 15.0000,  0.0000,  0.0000,  8.0292,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "78 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "79 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "80 - tensor([ 1.0000,  1.0000, 65.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "81 - tensor([ 2.0000,  1.0000, 62.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "82 - tensor([ 1.0000,  1.0000, 52.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "83 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "84 - tensor([  1.0000,   0.0000,  14.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   1.0000,   3.0000,   0.0000]): 1\n",
      "85 - tensor([ 3.0000,  0.0000, 14.5000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "86 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "87 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 12.8750,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "88 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "89 - tensor([ 3.0000,  1.0000, 28.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "90 - tensor([ 2.0000,  0.0000, 19.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "91 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  1.0000,  8.4042,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "92 - tensor([ 3.0000,  1.0000,  9.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "93 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "94 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "95 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "96 - tensor([ 3.0000,  0.0000, 19.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "97 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "98 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "99 - tensor([ 3.0000,  1.0000, 28.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "100 - tensor([ 3.0000,  1.0000,  4.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 0\n",
      "101 - tensor([ 2.0000,  1.0000, 29.0000,  1.0000,  0.0000, 27.7208,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "102 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "103 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.2167,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "104 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "105 - tensor([ 2.0000,  0.0000, 27.0000,  1.0000,  0.0000, 13.8583,  0.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "106 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "107 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6625,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "108 - tensor([ 2.0000,  1.0000,  0.6700,  1.0000,  1.0000, 14.5000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "109 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "110 - tensor([ 3.0000,  1.0000,  3.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 1\n",
      "111 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "112 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "113 - tensor([ 3.0000,  0.0000,  1.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "114 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "115 - tensor([ 1.0000,  1.0000, 49.0000,  1.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "116 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.7417,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "117 - tensor([ 3.0000,  0.0000,  2.0000,  0.0000,  1.0000, 12.2875,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "118 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "119 - tensor([ 2.0000,  1.0000, 42.0000,  1.0000,  0.0000, 27.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "120 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 15.7500,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "121 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  1.0000, 27.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "122 - tensor([ 3.0000,  1.0000, 41.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "123 - tensor([ 1.0000,  1.0000, 55.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "124 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "125 - tensor([ 3.0000,  1.0000,  9.0000,  1.0000,  1.0000, 15.9000,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "126 - tensor([ 3.0000,  1.0000, 27.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "127 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 30.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "128 - tensor([ 2.0000,  0.0000, 23.0000,  0.0000,  0.0000, 13.7917,  0.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "129 - tensor([ 3.0000,  1.0000,  7.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "130 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "131 - tensor([ 1.0000,  1.0000, 60.0000,  1.0000,  1.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "132 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "133 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "134 - tensor([ 3.0000,  0.0000, 35.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "135 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "136 - tensor([  1.0000,   0.0000,  23.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "137 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "138 - tensor([ 1.0000,  1.0000,  4.0000,  0.0000,  2.0000, 81.8583,  2.0000, 87.5090,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "139 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "140 - tensor([ 1.0000,  0.0000, 22.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "141 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "142 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.3875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "143 - tensor([ 2.0000,  0.0000, 57.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "144 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "145 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "146 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "147 - tensor([ 2.0000,  0.0000, 32.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "148 - tensor([ 3.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "149 - tensor([ 3.0000,  0.0000,  9.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "150 - tensor([ 2.0000,  0.0000, 14.0000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "151 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "152 - tensor([ 1.0000,  1.0000, 42.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "153 - tensor([ 3.0000,  0.0000, 10.0000,  0.0000,  2.0000, 24.1500,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "154 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  1.0000, 15.7417,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "155 - tensor([ 3.0000,  0.0000, 21.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "156 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "157 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 31.0000,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "158 - tensor([ 1.0000,  1.0000, 50.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "159 - tensor([  1.0000,   1.0000,  17.0000,   0.0000,   2.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 1\n",
      "160 - tensor([ 1.0000,  1.0000, 29.0000,  1.0000,  0.0000, 66.6000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "161 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.1708,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "162 - tensor([ 3.0000,  1.0000, 24.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "163 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  1.0000, 55.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "164 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "165 - tensor([ 1.0000,  1.0000, 46.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "166 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "167 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 0\n",
      "168 - tensor([ 2.0000,  0.0000, 32.5000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "169 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "170 - tensor([ 2.0000,  1.0000, 43.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "171 - tensor([ 3.0000,  1.0000, 36.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "172 - tensor([ 2.0000,  0.0000, 18.0000,  0.0000,  2.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "173 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "174 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "175 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "176 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "177 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "178 - tensor([ 3.0000,  1.0000, 37.0000,  2.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "179 - tensor([ 1.0000,  0.0000, 38.0000,  0.0000,  0.0000, 80.0000,  3.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "180 - tensor([ 1.0000,  1.0000, 21.0000,  0.0000,  1.0000, 77.2875,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "181 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "182 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "183 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  4.0125,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "184 - tensor([  1.0000,   0.0000,  40.0000,   1.0000,   1.0000, 134.5000,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "185 - tensor([ 3.0000,  1.0000, 45.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "186 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "187 - tensor([ 2.0000,  0.0000,  6.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "188 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "189 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "190 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "191 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.5208,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "192 - tensor([ 2.0000,  1.0000, 19.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "193 - tensor([ 3.0000,  1.0000, 14.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         2.0000,  7.0000,  0.0000]): 0\n",
      "194 - tensor([ 2.0000,  0.0000, 13.0000,  0.0000,  1.0000, 19.5000,  2.0000, 21.1792,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "195 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 19.9667,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "196 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "197 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7333,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "198 - tensor([ 3.0000,  0.0000, 21.0000,  2.0000,  2.0000, 34.3750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "199 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "200 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "201 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "202 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "203 - tensor([ 2.0000,  1.0000, 19.0000,  1.0000,  1.0000, 36.7500,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "204 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 14.0000,  2.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "205 - tensor([  1.0000,   1.0000,  49.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "206 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "207 - tensor([ 1.0000,  1.0000, 30.0000,  0.0000,  0.0000, 27.7500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "208 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "209 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "210 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.8625,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "211 - tensor([ 1.0000,  1.0000, 24.0000,  0.0000,  0.0000, 79.2000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "212 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.8583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "213 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "214 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "215 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "216 - tensor([ 2.0000,  0.0000, 29.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "217 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "218 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "219 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "220 - tensor([ 1.0000,  0.0000, 51.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "221 - tensor([ 3.0000,  1.0000,  8.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "222 - tensor([ 3.0000,  1.0000, 40.5000,  0.0000,  2.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "223 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "224 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "225 - tensor([ 2.0000,  0.0000, 42.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "226 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  6.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "227 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "228 - tensor([ 2.0000,  1.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "229 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "230 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "231 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "232 - tensor([ 1.0000,  1.0000, 51.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "233 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "234 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "235 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "236 - tensor([ 2.0000,  1.0000, 34.0000,  1.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "237 - tensor([ 3.0000,  0.0000, 20.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "238 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "239 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "240 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "241 - tensor([ 2.0000,  1.0000, 50.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "242 - tensor([ 2.0000,  1.0000, 31.0000,  1.0000,  1.0000, 37.0042,  0.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "243 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "244 - tensor([ 1.0000,  1.0000, 71.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "245 - tensor([  1.0000,   1.0000,  50.0000,   2.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   4.0000,   2.0000,   0.0000]): 1\n",
      "246 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "247 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "248 - tensor([ 1.0000,  0.0000, 16.0000,  0.0000,  1.0000, 39.4000,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "249 - tensor([ 3.0000,  1.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         2.0000,  6.0000,  0.0000]): 0\n",
      "250 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "251 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "252 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "253 - tensor([ 1.0000,  1.0000, 70.0000,  1.0000,  1.0000, 71.0000,  2.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "254 - tensor([ 2.0000,  1.0000, 27.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "255 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 1\n",
      "256 - tensor([ 2.0000,  0.0000, 25.0000,  1.0000,  1.0000, 30.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "257 - tensor([ 1.0000,  0.0000, 19.0000,  0.0000,  2.0000, 26.2833,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "258 - tensor([ 1.0000,  1.0000, 28.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "259 - tensor([ 2.0000,  1.0000, 52.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "260 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 25.5875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "261 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "262 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "263 - tensor([ 2.0000,  1.0000,  0.8300,  1.0000,  1.0000, 18.7500,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "264 - tensor([ 1.0000,  0.0000, 18.0000,  0.0000,  2.0000, 79.6500,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "265 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "266 - tensor([ 2.0000,  1.0000,  1.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "267 - tensor([ 2.0000,  1.0000, 36.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "268 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "269 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "270 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 133.6500,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "271 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000, 14.4542,  0.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "272 - tensor([ 2.0000,  0.0000, 40.0000,  1.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "273 - tensor([  1.0000,   1.0000,  27.0000,   0.0000,   2.0000, 211.5000,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "274 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "275 - tensor([ 2.0000,  1.0000, 21.0000,  0.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "276 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "277 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "278 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "279 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "280 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "281 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "282 - tensor([ 3.0000,  0.0000, 39.0000,  0.0000,  5.0000, 29.1250,  1.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "283 - tensor([  1.0000,   0.0000,  17.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "284 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 35.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "285 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "286 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "287 - tensor([ 1.0000,  0.0000, 21.0000,  0.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "288 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "289 - tensor([ 2.0000,  0.0000, 26.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "290 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "291 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.4583,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "292 - tensor([ 3.0000,  1.0000, 12.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "293 - tensor([  1.0000,   1.0000,  36.0000,   0.0000,   1.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 1\n",
      "294 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "295 - tensor([ 1.0000,  0.0000, 17.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "296 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  8.6542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "297 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 56.9292,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "298 - tensor([ 1.0000,  0.0000, 63.0000,  1.0000,  0.0000, 77.9583,  2.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "299 - tensor([ 3.0000,  1.0000, 11.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "300 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "301 - tensor([ 1.0000,  1.0000, 37.0000,  0.0000,  1.0000, 29.7000,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "302 - tensor([ 3.0000,  0.0000, 18.0000,  2.0000,  0.0000, 18.0000,  2.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 0\n",
      "303 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 31.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "304 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  0.0000, 55.9000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "305 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "306 - tensor([ 3.0000,  1.0000, 24.0000,  2.0000,  0.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "307 - tensor([  1.0000,   0.0000,   2.0000,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   3.0000,   0.0000]): 0\n",
      "308 - tensor([ 1.0000,  1.0000, 61.0000,  0.0000,  0.0000, 32.3208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "309 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 86.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "310 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "311 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 40.1250,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "312 - tensor([ 3.0000,  0.0000, 32.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "313 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "314 - tensor([ 2.0000,  0.0000, 40.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "315 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "316 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "317 - tensor([ 1.0000,  1.0000, 52.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "318 - tensor([ 2.0000,  0.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "319 - tensor([ 1.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.5500,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "320 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "321 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  1.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "322 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  2.0000, 11.1333,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "323 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "324 - tensor([ 3.0000,  1.0000, 24.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "325 - tensor([ 2.0000,  0.0000, 54.0000,  1.0000,  3.0000, 23.0000,  2.0000, 21.1792,\n",
      "         3.0000,  4.0000,  0.0000]): 1\n",
      "326 - tensor([ 2.0000,  1.0000, 37.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "327 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "328 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 22.5250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "329 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 110.8833,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "330 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  1.0000, 77.2875,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "331 - tensor([ 3.0000,  1.0000,  2.0000,  4.0000,  1.0000, 29.1250,  1.0000, 13.3029,\n",
      "         0.0000,  5.0000,  0.0000]): 0\n",
      "332 - tensor([ 3.0000,  0.0000,  0.7500,  2.0000,  1.0000, 19.2583,  0.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "333 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 69.3000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "334 - tensor([ 2.0000,  0.0000, 50.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "335 - tensor([ 3.0000,  0.0000, 41.0000,  0.0000,  5.0000, 39.6875,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "336 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "337 - tensor([ 1.0000,  0.0000, 54.0000,  1.0000,  0.0000, 59.4000,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "338 - tensor([ 3.0000,  0.0000, 38.0000,  1.0000,  5.0000, 31.3875,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 1\n",
      "339 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "340 - tensor([ 1.0000,  1.0000, 26.0000,  0.0000,  0.0000, 30.0000,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "341 - tensor([ 3.0000,  1.0000, 30.5000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "342 - tensor([ 3.0000,  1.0000, 48.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "343 - tensor([ 2.0000,  0.0000, 55.0000,  0.0000,  0.0000, 16.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "344 - tensor([ 3.0000,  0.0000, 13.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "345 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "346 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "347 - tensor([ 1.0000,  1.0000, 27.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "348 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "349 - tensor([ 2.0000,  1.0000, 30.0000,  1.0000,  0.0000, 24.0000,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "350 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "351 - tensor([ 1.0000,  0.0000, 30.0000,  0.0000,  0.0000, 93.5000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "352 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 53.1000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "353 - tensor([ 3.0000,  1.0000, 28.5000,  0.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "354 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  8.1375,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "355 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "356 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  6.9500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "357 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "358 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "359 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "360 - tensor([ 3.0000,  1.0000, 40.0000,  1.0000,  1.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "361 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "362 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "363 - tensor([ 3.0000,  1.0000, 14.0000,  4.0000,  1.0000, 39.6875,  2.0000, 13.3029,\n",
      "         2.0000,  5.0000,  0.0000]): 0\n",
      "364 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.4333,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "365 - tensor([ 1.0000,  1.0000, 32.0000,  0.0000,  0.0000, 30.5000,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "366 - tensor([ 1.0000,  1.0000, 48.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "367 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "368 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "369 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "370 - tensor([ 3.0000,  1.0000, 30.0000,  1.0000,  0.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "371 - tensor([ 1.0000,  1.0000, 31.0000,  1.0000,  0.0000, 57.0000,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "372 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "373 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "374 - tensor([ 3.0000,  1.0000, 35.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "375 - tensor([ 2.0000,  0.0000, 25.0000,  0.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "376 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 47.1000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "377 - tensor([ 1.0000,  0.0000, 19.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "378 - tensor([ 3.0000,  1.0000, 34.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "379 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "380 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "381 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "382 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "383 - tensor([ 2.0000,  0.0000, 24.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "384 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "385 - tensor([ 3.0000,  1.0000, 34.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "386 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "387 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "388 - tensor([ 1.0000,  0.0000, 60.0000,  1.0000,  0.0000, 75.2500,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "389 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "390 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "391 - tensor([  1.0000,   0.0000,  40.0000,   0.0000,   0.0000, 153.4625,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "392 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "393 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000, 18.7875,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "394 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "395 - tensor([ 3.0000,  1.0000, 31.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "396 - tensor([ 3.0000,  0.0000, 16.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         1.0000,  7.0000,  0.0000]): 0\n",
      "397 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  2.0000, 16.7000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "398 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  0.0000, 27.7208,  0.0000, 87.5090,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "399 - tensor([ 3.0000,  1.0000, 43.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "400 - tensor([ 2.0000,  1.0000, 44.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "401 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "402 - tensor([ 2.0000,  1.0000,  2.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "403 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "404 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "405 - tensor([ 2.0000,  0.0000, 29.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "406 - tensor([ 1.0000,  1.0000, 28.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "407 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "408 - tensor([ 3.0000,  1.0000, 47.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "409 - tensor([ 3.0000,  1.0000, 59.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "410 - tensor([ 3.0000,  1.0000, 45.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "411 - tensor([ 1.0000,  0.0000, 36.0000,  0.0000,  2.0000, 71.0000,  2.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "412 - tensor([ 2.0000,  0.0000, 45.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "413 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 24.1500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "414 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "415 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "416 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 11.1333,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "417 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "418 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "419 - tensor([ 2.0000,  0.0000, 33.0000,  1.0000,  2.0000, 27.7500,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "420 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "421 - tensor([ 2.0000,  0.0000,  4.0000,  1.0000,  1.0000, 23.0000,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "422 - tensor([ 3.0000,  0.0000, 45.0000,  1.0000,  4.0000, 27.9000,  2.0000, 13.3029,\n",
      "         3.0000,  5.0000,  0.0000]): 0\n",
      "423 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "424 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "425 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "426 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "427 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "428 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "429 - tensor([ 2.0000,  0.0000, 28.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "430 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "431 - tensor([ 3.0000,  1.0000,  4.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         0.0000, 10.0000,  0.0000]): 0\n",
      "432 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 89.1042,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "433 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "434 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "435 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "436 - tensor([  1.0000,   0.0000,  25.0000,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   3.0000,   3.0000,   0.0000]): 0\n",
      "437 - tensor([ 1.0000,  0.0000, 19.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "438 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "439 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  2.0000, 23.4500,  2.0000, 13.3029,\n",
      "         1.0000,  3.0000,  0.0000]): 0\n",
      "440 - tensor([ 3.0000,  0.0000, 20.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "441 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "442 - tensor([  1.0000,   0.0000,  50.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "443 - tensor([ 3.0000,  1.0000, 42.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "444 - tensor([  1.0000,   0.0000,  39.0000,   1.0000,   1.0000, 110.8833,   0.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "445 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  6.9750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "446 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 55.4417,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "447 - tensor([ 2.0000,  1.0000, 18.0000,  0.0000,  0.0000, 11.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "448 - tensor([ 2.0000,  0.0000, 30.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "449 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "450 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "451 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "452 - tensor([ 3.0000,  1.0000, 11.0000,  5.0000,  2.0000, 46.9000,  2.0000, 13.3029,\n",
      "         0.0000,  7.0000,  0.0000]): 0\n",
      "453 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 15.0458,  0.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "454 - tensor([ 2.0000,  0.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "455 - tensor([  1.0000,   0.0000,  45.0000,   1.0000,   1.0000, 164.8667,   2.0000,\n",
      "         87.5090,   3.0000,   2.0000,   0.0000]): 1\n",
      "456 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "457 - tensor([ 2.0000,  0.0000, 28.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "458 - tensor([ 3.0000,  0.0000, 21.0000,  1.0000,  0.0000,  9.8250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "459 - tensor([ 2.0000,  1.0000, 46.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "460 - tensor([ 3.0000,  0.0000, 39.0000,  1.0000,  5.0000, 31.2750,  2.0000, 13.3029,\n",
      "         3.0000,  6.0000,  0.0000]): 0\n",
      "461 - tensor([  1.0000,   0.0000,  23.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "462 - tensor([ 3.0000,  1.0000, 20.5000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "463 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "464 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "465 - tensor([ 2.0000,  1.0000,  3.0000,  1.0000,  1.0000, 26.0000,  2.0000, 21.1792,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "466 - tensor([ 2.0000,  1.0000, 25.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "467 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "468 - tensor([ 3.0000,  1.0000,  9.0000,  0.0000,  2.0000, 20.5250,  2.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "469 - tensor([ 1.0000,  1.0000, 47.0000,  0.0000,  0.0000, 34.0208,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "470 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "471 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  6.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "472 - tensor([ 2.0000,  0.0000, 19.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "473 - tensor([ 2.0000,  0.0000,  3.0000,  1.0000,  2.0000, 41.5792,  0.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "474 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "475 - tensor([ 1.0000,  1.0000, 36.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "476 - tensor([ 2.0000,  1.0000, 33.0000,  0.0000,  0.0000, 12.2750,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "477 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "478 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "479 - tensor([ 3.0000,  0.0000, 45.0000,  0.0000,  1.0000, 14.4542,  0.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "480 - tensor([ 3.0000,  1.0000, 20.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "481 - tensor([ 3.0000,  0.0000, 28.0000,  1.0000,  1.0000, 14.4000,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "482 - tensor([ 1.0000,  0.0000, 53.0000,  2.0000,  0.0000, 51.4792,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "483 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "484 - tensor([ 2.0000,  0.0000, 22.0000,  1.0000,  1.0000, 29.0000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "485 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "486 - tensor([ 3.0000,  0.0000,  2.0000,  3.0000,  2.0000, 27.9000,  2.0000, 13.3029,\n",
      "         1.0000,  5.0000,  0.0000]): 0\n",
      "487 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "488 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "489 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "490 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  0.0000, 15.5500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "491 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "492 - tensor([ 3.0000,  1.0000, 39.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "493 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "494 - tensor([ 2.0000,  1.0000, 30.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "495 - tensor([ 3.0000,  0.0000, 19.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "496 - tensor([ 3.0000,  1.0000,  0.4200,  0.0000,  1.0000,  8.5167,  0.0000, 13.3029,\n",
      "         0.0000,  1.0000,  0.0000]): 1\n",
      "497 - tensor([ 1.0000,  1.0000, 42.0000,  0.0000,  0.0000, 26.2875,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "498 - tensor([ 1.0000,  0.0000, 26.0000,  0.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "499 - tensor([ 3.0000,  0.0000, 17.0000,  4.0000,  2.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 1\n",
      "500 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.1125,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "501 - tensor([ 2.0000,  1.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "502 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "503 - tensor([ 1.0000,  0.0000, 33.0000,  1.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "504 - tensor([ 1.0000,  0.0000, 52.0000,  1.0000,  0.0000, 78.2667,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "505 - tensor([ 3.0000,  1.0000, 41.0000,  2.0000,  0.0000, 14.1083,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "506 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "507 - tensor([ 1.0000,  1.0000, 48.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "508 - tensor([ 2.0000,  1.0000, 28.0000,  0.0000,  1.0000, 33.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "509 - tensor([  1.0000,   0.0000,  36.0000,   0.0000,   0.0000, 135.6333,   0.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "510 - tensor([ 1.0000,  0.0000, 38.0000,  1.0000,  0.0000, 71.2833,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "511 - tensor([ 1.0000,  1.0000, 45.0000,  1.0000,  0.0000, 83.4750,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "512 - tensor([ 1.0000,  1.0000, 25.0000,  1.0000,  0.0000, 91.0792,  0.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "513 - tensor([ 1.0000,  0.0000, 35.0000,  1.0000,  0.0000, 90.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "514 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "515 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 25.9250,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "516 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000,  7.0458,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "517 - tensor([ 2.0000,  1.0000, 54.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "518 - tensor([ 3.0000,  0.0000, 31.0000,  1.0000,  1.0000, 20.5250,  2.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "519 - tensor([ 2.0000,  0.0000, 27.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "520 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "521 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "522 - tensor([  1.0000,   0.0000,  22.0000,   0.0000,   0.0000, 151.5500,   2.0000,\n",
      "         87.5090,   1.0000,   0.0000,   1.0000]): 1\n",
      "523 - tensor([  1.0000,   0.0000,  31.0000,   1.0000,   0.0000, 113.2750,   0.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "524 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "525 - tensor([ 3.0000,  1.0000, 65.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "526 - tensor([ 3.0000,  0.0000,  6.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "527 - tensor([ 2.0000,  1.0000, 34.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "528 - tensor([ 3.0000,  1.0000,  1.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         0.0000,  3.0000,  0.0000]): 1\n",
      "529 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "530 - tensor([ 3.0000,  0.0000, 40.0000,  1.0000,  0.0000,  9.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "531 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  1.0000, 16.1000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "532 - tensor([ 3.0000,  1.0000, 26.0000,  0.0000,  0.0000,  7.8875,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "533 - tensor([ 1.0000,  1.0000, 62.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "534 - tensor([ 3.0000,  1.0000, 23.0000,  0.0000,  0.0000,  7.8542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "535 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7750,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "536 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "537 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "538 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "539 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.2250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "540 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "541 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "542 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "543 - tensor([ 3.0000,  1.0000, 17.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "544 - tensor([ 1.0000,  0.0000, 24.0000,  0.0000,  0.0000, 49.5042,  0.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 1\n",
      "545 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "546 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "547 - tensor([ 2.0000,  0.0000, 31.0000,  1.0000,  1.0000, 26.2500,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "548 - tensor([ 3.0000,  0.0000, 47.0000,  1.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 0\n",
      "549 - tensor([ 3.0000,  1.0000, 61.0000,  0.0000,  0.0000,  6.2375,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "550 - tensor([ 1.0000,  1.0000, 37.0000,  1.0000,  1.0000, 52.5542,  2.0000, 87.5090,\n",
      "         2.0000,  2.0000,  0.0000]): 1\n",
      "551 - tensor([ 3.0000,  1.0000, 49.0000,  0.0000,  0.0000,  0.0000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "552 - tensor([ 3.0000,  1.0000, 36.0000,  1.0000,  1.0000, 24.1500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "553 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "554 - tensor([ 1.0000,  1.0000, 54.0000,  0.0000,  0.0000, 51.8625,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "555 - tensor([ 1.0000,  1.0000, 27.0000,  0.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "556 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "557 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "558 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.6500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "559 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.5500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "560 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7292,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "561 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "562 - tensor([ 3.0000,  0.0000,  2.0000,  0.0000,  1.0000, 10.4625,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "563 - tensor([ 3.0000,  0.0000, 14.0000,  1.0000,  0.0000, 11.2417,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "564 - tensor([ 3.0000,  1.0000, 23.5000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "565 - tensor([ 1.0000,  1.0000, 38.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "566 - tensor([ 3.0000,  0.0000, 27.0000,  0.0000,  1.0000, 12.4750,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "567 - tensor([ 3.0000,  1.0000, 24.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "568 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 221.7792,   2.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "569 - tensor([ 3.0000,  1.0000, 20.0000,  0.0000,  0.0000,  9.8458,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "570 - tensor([ 2.0000,  0.0000, 36.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "571 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "572 - tensor([ 1.0000,  1.0000, 45.0000,  0.0000,  0.0000, 35.5000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "573 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "574 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000, 14.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "575 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "576 - tensor([ 2.0000,  0.0000, 24.0000,  2.0000,  3.0000, 18.7500,  2.0000, 21.1792,\n",
      "         3.0000,  5.0000,  0.0000]): 1\n",
      "577 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 52.0000,  2.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "578 - tensor([ 3.0000,  0.0000, 36.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "579 - tensor([ 3.0000,  1.0000, 30.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "580 - tensor([ 3.0000,  0.0000, 33.0000,  3.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "581 - tensor([  1.0000,   1.0000,  19.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "582 - tensor([ 3.0000,  0.0000,  5.0000,  0.0000,  0.0000, 12.4750,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "583 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.1250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "584 - tensor([ 3.0000,  0.0000, 29.0000,  0.0000,  4.0000, 21.0750,  2.0000, 13.3029,\n",
      "         3.0000,  4.0000,  0.0000]): 0\n",
      "585 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "586 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "587 - tensor([ 1.0000,  0.0000, 56.0000,  0.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "588 - tensor([  1.0000,   1.0000,  35.0000,   0.0000,   0.0000, 512.3292,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 1\n",
      "589 - tensor([ 2.0000,  0.0000,  7.0000,  0.0000,  2.0000, 26.2500,  2.0000, 21.1792,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "590 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "591 - tensor([ 2.0000,  1.0000, 29.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "592 - tensor([ 2.0000,  1.0000, 39.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "593 - tensor([ 3.0000,  1.0000, 29.0000,  1.0000,  0.0000, 15.5000,  1.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "594 - tensor([  1.0000,   0.0000,  15.0000,   0.0000,   1.0000, 211.3375,   2.0000,\n",
      "         87.5090,   1.0000,   1.0000,   0.0000]): 1\n",
      "595 - tensor([  1.0000,   0.0000,  36.0000,   1.0000,   0.0000, 146.5208,   0.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "596 - tensor([ 1.0000,  0.0000, 36.0000,  1.0000,  0.0000, 82.1708,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "597 - tensor([ 2.0000,  1.0000, 23.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "598 - tensor([ 1.0000,  0.0000, 58.0000,  0.0000,  0.0000, 26.5500,  2.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "599 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "600 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7250,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "601 - tensor([ 3.0000,  0.0000, 31.0000,  0.0000,  0.0000,  8.6833,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "602 - tensor([ 3.0000,  1.0000, 38.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "603 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  9.8417,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "604 - tensor([ 2.0000,  0.0000, 35.0000,  0.0000,  0.0000, 21.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "605 - tensor([ 3.0000,  1.0000, 51.0000,  0.0000,  0.0000,  7.0542,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "606 - tensor([ 1.0000,  0.0000, 32.0000,  0.0000,  0.0000, 76.2917,  0.0000, 87.5090,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "607 - tensor([ 3.0000,  0.0000, 18.0000,  0.0000,  0.0000,  7.4958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "608 - tensor([ 3.0000,  0.0000, 16.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "609 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "610 - tensor([ 3.0000,  1.0000, 19.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "611 - tensor([ 2.0000,  1.0000, 57.0000,  0.0000,  0.0000, 12.3500,  1.0000, 21.1792,\n",
      "         4.0000,  0.0000,  1.0000]): 0\n",
      "612 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "613 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 79.6500,  2.0000, 87.5090,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "614 - tensor([ 3.0000,  0.0000, 22.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         1.0000, 10.0000,  0.0000]): 0\n",
      "615 - tensor([ 3.0000,  1.0000, 17.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "616 - tensor([ 3.0000,  0.0000, 24.0000,  0.0000,  3.0000, 19.2583,  0.0000, 13.3029,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "617 - tensor([  1.0000,   1.0000,  38.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "618 - tensor([ 2.0000,  1.0000, 21.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "619 - tensor([ 3.0000,  1.0000, 16.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "620 - tensor([ 2.0000,  1.0000, 32.5000,  1.0000,  0.0000, 30.0708,  0.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "621 - tensor([  1.0000,   1.0000,  64.0000,   1.0000,   4.0000, 263.0000,   2.0000,\n",
      "         87.5090,   2.0000,   5.0000,   0.0000]): 0\n",
      "622 - tensor([ 2.0000,  0.0000, 48.0000,  1.0000,  2.0000, 65.0000,  2.0000, 21.1792,\n",
      "         3.0000,  3.0000,  0.0000]): 1\n",
      "623 - tensor([ 3.0000,  1.0000, 29.0000,  8.0000,  2.0000, 69.5500,  2.0000, 13.3029,\n",
      "         2.0000, 10.0000,  0.0000]): 0\n",
      "624 - tensor([ 1.0000,  1.0000, 44.0000,  2.0000,  0.0000, 90.0000,  1.0000, 87.5090,\n",
      "         4.0000,  2.0000,  0.0000]): 0\n",
      "625 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "626 - tensor([ 3.0000,  0.0000, 25.0000,  1.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 0\n",
      "627 - tensor([ 2.0000,  0.0000, 45.0000,  0.0000,  0.0000, 13.5000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "628 - tensor([ 3.0000,  0.0000,  4.0000,  0.0000,  1.0000, 13.4167,  0.0000, 13.3029,\n",
      "         1.0000,  1.0000,  0.0000]): 1\n",
      "629 - tensor([ 3.0000,  0.0000,  3.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "630 - tensor([ 3.0000,  1.0000, 18.0000,  0.0000,  0.0000,  7.7958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "631 - tensor([ 1.0000,  0.0000, 39.0000,  1.0000,  1.0000, 83.1583,  0.0000, 87.5090,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "632 - tensor([ 1.0000,  0.0000, 44.0000,  0.0000,  1.0000, 57.9792,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "633 - tensor([ 2.0000,  1.0000, 35.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "634 - tensor([ 1.0000,  1.0000, 31.0000,  0.0000,  0.0000, 50.4958,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "635 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "636 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "637 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "638 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 22.3583,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "639 - tensor([ 2.0000,  1.0000, 36.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "640 - tensor([ 3.0000,  1.0000, 18.0000,  1.0000,  0.0000,  6.4958,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "641 - tensor([ 3.0000,  1.0000,  9.0000,  4.0000,  2.0000, 31.3875,  2.0000, 13.3029,\n",
      "         0.0000,  6.0000,  0.0000]): 0\n",
      "642 - tensor([ 3.0000,  1.0000, 21.0000,  0.0000,  0.0000,  7.8000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "643 - tensor([  1.0000,   1.0000,  58.0000,   0.0000,   2.0000, 113.2750,   0.0000,\n",
      "         87.5090,   2.0000,   2.0000,   0.0000]): 0\n",
      "644 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "645 - tensor([ 3.0000,  1.0000, 33.0000,  0.0000,  0.0000,  9.5000,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "646 - tensor([ 3.0000,  0.0000, 17.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "647 - tensor([ 2.0000,  0.0000, 22.0000,  0.0000,  0.0000, 33.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "648 - tensor([ 1.0000,  0.0000, 48.0000,  1.0000,  0.0000, 39.6000,  0.0000, 87.5090,\n",
      "         4.0000,  1.0000,  0.0000]): 1\n",
      "649 - tensor([  1.0000,   0.0000,  24.0000,   3.0000,   2.0000, 263.0000,   2.0000,\n",
      "         87.5090,   1.0000,   5.0000,   0.0000]): 1\n",
      "650 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "651 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.6625,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "652 - tensor([ 3.0000,  0.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "653 - tensor([ 2.0000,  0.0000, 38.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "654 - tensor([ 3.0000,  1.0000, 28.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "655 - tensor([ 3.0000,  0.0000, 63.0000,  0.0000,  0.0000,  9.5875,  2.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "656 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "657 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.8958,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "658 - tensor([ 3.0000,  1.0000, 22.0000,  0.0000,  0.0000,  9.3500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "659 - tensor([ 1.0000,  1.0000, 56.0000,  0.0000,  0.0000, 30.6958,  0.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "660 - tensor([ 3.0000,  1.0000, 33.0000,  1.0000,  1.0000, 20.5250,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "661 - tensor([ 3.0000,  1.0000, 40.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "662 - tensor([ 3.0000,  1.0000, 25.0000,  1.0000,  0.0000, 17.8000,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "663 - tensor([ 2.0000,  1.0000, 24.0000,  2.0000,  0.0000, 73.5000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "664 - tensor([ 2.0000,  1.0000, 32.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  1.0000,  0.0000]): 1\n",
      "665 - tensor([  1.0000,   1.0000,   0.9200,   1.0000,   2.0000, 151.5500,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "666 - tensor([ 3.0000,  0.0000, 22.0000,  1.0000,  1.0000, 22.3583,  0.0000, 13.3029,\n",
      "         1.0000,  2.0000,  0.0000]): 1\n",
      "667 - tensor([ 3.0000,  1.0000,  2.0000,  3.0000,  1.0000, 21.0750,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "668 - tensor([ 1.0000,  0.0000, 49.0000,  1.0000,  0.0000, 76.7292,  0.0000, 87.5090,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "669 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "670 - tensor([ 1.0000,  1.0000, 29.0000,  0.0000,  0.0000,  0.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "671 - tensor([ 2.0000,  1.0000, 25.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "672 - tensor([ 3.0000,  0.0000,  2.0000,  4.0000,  2.0000, 31.2750,  2.0000, 13.3029,\n",
      "         1.0000,  6.0000,  0.0000]): 0\n",
      "673 - tensor([ 3.0000,  1.0000, 26.0000,  1.0000,  2.0000, 20.5750,  2.0000, 13.3029,\n",
      "         2.0000,  3.0000,  0.0000]): 0\n",
      "674 - tensor([ 1.0000,  1.0000, 64.0000,  0.0000,  0.0000, 26.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "675 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "676 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000,  7.2250,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "677 - tensor([ 3.0000,  1.0000, 27.0000,  0.0000,  0.0000,  7.8958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "678 - tensor([ 2.0000,  1.0000, 36.5000,  0.0000,  2.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "679 - tensor([ 3.0000,  1.0000, 29.0000,  0.0000,  0.0000, 14.4583,  0.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "680 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "681 - tensor([ 2.0000,  1.0000, 31.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "682 - tensor([ 2.0000,  0.0000,  4.0000,  2.0000,  1.0000, 39.0000,  2.0000, 21.1792,\n",
      "         1.0000,  3.0000,  0.0000]): 1\n",
      "683 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000, 56.4958,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "684 - tensor([ 3.0000,  1.0000, 50.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "685 - tensor([ 3.0000,  0.0000, 24.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         3.0000,  1.0000,  0.0000]): 1\n",
      "686 - tensor([ 3.0000,  0.0000, 22.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         1.0000,  4.0000,  0.0000]): 0\n",
      "687 - tensor([ 3.0000,  1.0000, 25.0000,  0.0000,  0.0000,  7.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "688 - tensor([  1.0000,   0.0000,  58.0000,   0.0000,   1.0000, 153.4625,   2.0000,\n",
      "         87.5090,   3.0000,   1.0000,   0.0000]): 1\n",
      "689 - tensor([ 3.0000,  0.0000, 23.0000,  0.0000,  0.0000,  7.9250,  2.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "690 - tensor([  1.0000,   1.0000,  29.0000,   0.0000,   0.0000, 227.5250,   0.0000,\n",
      "         87.5090,   2.0000,   0.0000,   1.0000]): 0\n",
      "691 - tensor([  1.0000,   1.0000,  24.0000,   0.0000,   1.0000, 247.5208,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "692 - tensor([ 3.0000,  1.0000,  4.0000,  1.0000,  1.0000, 15.2458,  0.0000, 13.3029,\n",
      "         0.0000,  2.0000,  0.0000]): 1\n",
      "693 - tensor([ 2.0000,  1.0000, 16.0000,  0.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "694 - tensor([ 2.0000,  1.0000, 54.0000,  1.0000,  0.0000, 26.0000,  2.0000, 21.1792,\n",
      "         4.0000,  1.0000,  0.0000]): 0\n",
      "695 - tensor([ 3.0000,  1.0000,  4.0000,  3.0000,  1.0000, 25.4667,  2.0000, 13.3029,\n",
      "         0.0000,  4.0000,  0.0000]): 0\n",
      "696 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  2.0000, 15.2458,  0.0000, 13.3029,\n",
      "         3.0000,  2.0000,  0.0000]): 0\n",
      "697 - tensor([ 3.0000,  1.0000, 44.0000,  0.0000,  0.0000,  8.0500,  2.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "698 - tensor([ 3.0000,  1.0000, 15.0000,  1.0000,  1.0000,  7.2292,  0.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "699 - tensor([  1.0000,   1.0000,  11.0000,   1.0000,   2.0000, 120.0000,   2.0000,\n",
      "         87.5090,   0.0000,   3.0000,   0.0000]): 1\n",
      "700 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.8792,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "701 - tensor([ 2.0000,  1.0000, 70.0000,  0.0000,  0.0000, 10.5000,  2.0000, 21.1792,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "702 - tensor([ 3.0000,  0.0000, 30.5000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 0\n",
      "703 - tensor([ 3.0000,  1.0000, 32.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         2.0000,  0.0000,  1.0000]): 0\n",
      "704 - tensor([ 3.0000,  1.0000, 16.0000,  1.0000,  1.0000, 20.2500,  2.0000, 13.3029,\n",
      "         2.0000,  2.0000,  0.0000]): 0\n",
      "705 - tensor([ 2.0000,  0.0000, 24.0000,  0.0000,  2.0000, 14.5000,  2.0000, 21.1792,\n",
      "         3.0000,  2.0000,  0.0000]): 1\n",
      "706 - tensor([ 3.0000,  0.0000, 36.0000,  0.0000,  0.0000,  7.2292,  0.0000, 13.3029,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "707 - tensor([ 3.0000,  0.0000, 22.0000,  0.0000,  0.0000,  7.7500,  1.0000, 13.3029,\n",
      "         1.0000,  0.0000,  1.0000]): 1\n",
      "708 - tensor([  1.0000,   1.0000,  18.0000,   1.0000,   0.0000, 108.9000,   0.0000,\n",
      "         87.5090,   2.0000,   1.0000,   0.0000]): 0\n",
      "709 - tensor([ 3.0000,  1.0000, 32.0000,  1.0000,  0.0000, 15.8500,  2.0000, 13.3029,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "710 - tensor([ 1.0000,  1.0000, 80.0000,  0.0000,  0.0000, 30.0000,  2.0000, 87.5090,\n",
      "         2.0000,  0.0000,  1.0000]): 1\n",
      "711 - tensor([ 1.0000,  1.0000, 36.0000,  1.0000,  0.0000, 78.8500,  2.0000, 87.5090,\n",
      "         2.0000,  1.0000,  0.0000]): 0\n",
      "712 - tensor([ 2.0000,  0.0000, 42.0000,  0.0000,  0.0000, 13.0000,  2.0000, 21.1792,\n",
      "         3.0000,  0.0000,  1.0000]): 1\n",
      "################################################## 2\n",
      "[TRAIN]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([16, 11]): torch.Size([16])\n",
      "12 - torch.Size([16, 11]): torch.Size([16])\n",
      "13 - torch.Size([16, 11]): torch.Size([16])\n",
      "14 - torch.Size([16, 11]): torch.Size([16])\n",
      "15 - torch.Size([16, 11]): torch.Size([16])\n",
      "16 - torch.Size([16, 11]): torch.Size([16])\n",
      "17 - torch.Size([16, 11]): torch.Size([16])\n",
      "18 - torch.Size([16, 11]): torch.Size([16])\n",
      "19 - torch.Size([16, 11]): torch.Size([16])\n",
      "20 - torch.Size([16, 11]): torch.Size([16])\n",
      "21 - torch.Size([16, 11]): torch.Size([16])\n",
      "22 - torch.Size([16, 11]): torch.Size([16])\n",
      "23 - torch.Size([16, 11]): torch.Size([16])\n",
      "24 - torch.Size([16, 11]): torch.Size([16])\n",
      "25 - torch.Size([16, 11]): torch.Size([16])\n",
      "26 - torch.Size([16, 11]): torch.Size([16])\n",
      "27 - torch.Size([16, 11]): torch.Size([16])\n",
      "28 - torch.Size([16, 11]): torch.Size([16])\n",
      "29 - torch.Size([16, 11]): torch.Size([16])\n",
      "30 - torch.Size([16, 11]): torch.Size([16])\n",
      "31 - torch.Size([16, 11]): torch.Size([16])\n",
      "32 - torch.Size([16, 11]): torch.Size([16])\n",
      "33 - torch.Size([16, 11]): torch.Size([16])\n",
      "34 - torch.Size([16, 11]): torch.Size([16])\n",
      "35 - torch.Size([16, 11]): torch.Size([16])\n",
      "36 - torch.Size([16, 11]): torch.Size([16])\n",
      "37 - torch.Size([16, 11]): torch.Size([16])\n",
      "38 - torch.Size([16, 11]): torch.Size([16])\n",
      "39 - torch.Size([16, 11]): torch.Size([16])\n",
      "40 - torch.Size([16, 11]): torch.Size([16])\n",
      "41 - torch.Size([16, 11]): torch.Size([16])\n",
      "42 - torch.Size([16, 11]): torch.Size([16])\n",
      "43 - torch.Size([16, 11]): torch.Size([16])\n",
      "44 - torch.Size([9, 11]): torch.Size([9])\n",
      "[VALIDATION]\n",
      "0 - torch.Size([16, 11]): torch.Size([16])\n",
      "1 - torch.Size([16, 11]): torch.Size([16])\n",
      "2 - torch.Size([16, 11]): torch.Size([16])\n",
      "3 - torch.Size([16, 11]): torch.Size([16])\n",
      "4 - torch.Size([16, 11]): torch.Size([16])\n",
      "5 - torch.Size([16, 11]): torch.Size([16])\n",
      "6 - torch.Size([16, 11]): torch.Size([16])\n",
      "7 - torch.Size([16, 11]): torch.Size([16])\n",
      "8 - torch.Size([16, 11]): torch.Size([16])\n",
      "9 - torch.Size([16, 11]): torch.Size([16])\n",
      "10 - torch.Size([16, 11]): torch.Size([16])\n",
      "11 - torch.Size([2, 11]): torch.Size([2])\n",
      "################################################## 3\n",
      "[TEST]\n",
      "torch.Size([418, 11])\n",
      "892 1\n",
      "893 1\n",
      "894 1\n",
      "895 1\n",
      "896 0\n",
      "897 0\n",
      "898 1\n",
      "899 0\n",
      "900 1\n",
      "901 0\n",
      "902 1\n",
      "903 0\n",
      "904 0\n",
      "905 1\n",
      "906 0\n",
      "907 0\n",
      "908 1\n",
      "909 1\n",
      "910 1\n",
      "911 1\n",
      "912 0\n",
      "913 0\n",
      "914 0\n",
      "915 0\n",
      "916 0\n",
      "917 1\n",
      "918 0\n",
      "919 1\n",
      "920 0\n",
      "921 0\n",
      "922 1\n",
      "923 0\n",
      "924 0\n",
      "925 0\n",
      "926 0\n",
      "927 1\n",
      "928 1\n",
      "929 0\n",
      "930 1\n",
      "931 0\n",
      "932 1\n",
      "933 0\n",
      "934 1\n",
      "935 0\n",
      "936 0\n",
      "937 1\n",
      "938 0\n",
      "939 1\n",
      "940 0\n",
      "941 1\n",
      "942 0\n",
      "943 0\n",
      "944 0\n",
      "945 0\n",
      "946 0\n",
      "947 0\n",
      "948 1\n",
      "949 1\n",
      "950 0\n",
      "951 0\n",
      "952 0\n",
      "953 1\n",
      "954 0\n",
      "955 1\n",
      "956 0\n",
      "957 0\n",
      "958 0\n",
      "959 0\n",
      "960 0\n",
      "961 0\n",
      "962 1\n",
      "963 1\n",
      "964 1\n",
      "965 0\n",
      "966 0\n",
      "967 0\n",
      "968 1\n",
      "969 0\n",
      "970 0\n",
      "971 1\n",
      "972 0\n",
      "973 0\n",
      "974 0\n",
      "975 1\n",
      "976 1\n",
      "977 1\n",
      "978 1\n",
      "979 0\n",
      "980 1\n",
      "981 0\n",
      "982 0\n",
      "983 1\n",
      "984 0\n",
      "985 1\n",
      "986 0\n",
      "987 1\n",
      "988 0\n",
      "989 1\n",
      "990 0\n",
      "991 1\n",
      "992 0\n",
      "993 0\n",
      "994 1\n",
      "995 1\n",
      "996 0\n",
      "997 0\n",
      "998 1\n",
      "999 1\n",
      "1000 1\n",
      "1001 0\n",
      "1002 1\n",
      "1003 1\n",
      "1004 0\n",
      "1005 0\n",
      "1006 0\n",
      "1007 0\n",
      "1008 1\n",
      "1009 0\n",
      "1010 0\n",
      "1011 0\n",
      "1012 0\n",
      "1013 1\n",
      "1014 0\n",
      "1015 1\n",
      "1016 1\n",
      "1017 0\n",
      "1018 1\n",
      "1019 0\n",
      "1020 1\n",
      "1021 1\n",
      "1022 1\n",
      "1023 0\n",
      "1024 0\n",
      "1025 1\n",
      "1026 1\n",
      "1027 1\n",
      "1028 1\n",
      "1029 0\n",
      "1030 1\n",
      "1031 0\n",
      "1032 0\n",
      "1033 0\n",
      "1034 0\n",
      "1035 0\n",
      "1036 0\n",
      "1037 0\n",
      "1038 0\n",
      "1039 1\n",
      "1040 0\n",
      "1041 0\n",
      "1042 0\n",
      "1043 1\n",
      "1044 1\n",
      "1045 1\n",
      "1046 0\n",
      "1047 1\n",
      "1048 0\n",
      "1049 1\n",
      "1050 0\n",
      "1051 0\n",
      "1052 1\n",
      "1053 0\n",
      "1054 0\n",
      "1055 1\n",
      "1056 1\n",
      "1057 0\n",
      "1058 0\n",
      "1059 0\n",
      "1060 0\n",
      "1061 0\n",
      "1062 1\n",
      "1063 1\n",
      "1064 0\n",
      "1065 1\n",
      "1066 0\n",
      "1067 0\n",
      "1068 0\n",
      "1069 0\n",
      "1070 0\n",
      "1071 0\n",
      "1072 0\n",
      "1073 0\n",
      "1074 0\n",
      "1075 1\n",
      "1076 0\n",
      "1077 1\n",
      "1078 0\n",
      "1079 0\n",
      "1080 0\n",
      "1081 1\n",
      "1082 0\n",
      "1083 0\n",
      "1084 0\n",
      "1085 1\n",
      "1086 0\n",
      "1087 1\n",
      "1088 0\n",
      "1089 0\n",
      "1090 0\n",
      "1091 1\n",
      "1092 0\n",
      "1093 0\n",
      "1094 0\n",
      "1095 0\n",
      "1096 0\n",
      "1097 0\n",
      "1098 1\n",
      "1099 0\n",
      "1100 0\n",
      "1101 1\n",
      "1102 0\n",
      "1103 1\n",
      "1104 0\n",
      "1105 1\n",
      "1106 1\n",
      "1107 0\n",
      "1108 1\n",
      "1109 0\n",
      "1110 0\n",
      "1111 1\n",
      "1112 0\n",
      "1113 1\n",
      "1114 0\n",
      "1115 1\n",
      "1116 0\n",
      "1117 1\n",
      "1118 1\n",
      "1119 1\n",
      "1120 1\n",
      "1121 1\n",
      "1122 0\n",
      "1123 0\n",
      "1124 1\n",
      "1125 1\n",
      "1126 0\n",
      "1127 0\n",
      "1128 0\n",
      "1129 1\n",
      "1130 0\n",
      "1131 0\n",
      "1132 0\n",
      "1133 0\n",
      "1134 0\n",
      "1135 1\n",
      "1136 0\n",
      "1137 0\n",
      "1138 0\n",
      "1139 0\n",
      "1140 0\n",
      "1141 1\n",
      "1142 0\n",
      "1143 0\n",
      "1144 0\n",
      "1145 1\n",
      "1146 1\n",
      "1147 1\n",
      "1148 1\n",
      "1149 1\n",
      "1150 0\n",
      "1151 1\n",
      "1152 1\n",
      "1153 1\n",
      "1154 0\n",
      "1155 0\n",
      "1156 1\n",
      "1157 1\n",
      "1158 0\n",
      "1159 1\n",
      "1160 1\n",
      "1161 0\n",
      "1162 0\n",
      "1163 1\n",
      "1164 0\n",
      "1165 0\n",
      "1166 1\n",
      "1167 0\n",
      "1168 0\n",
      "1169 0\n",
      "1170 0\n",
      "1171 0\n",
      "1172 1\n",
      "1173 0\n",
      "1174 1\n",
      "1175 0\n",
      "1176 0\n",
      "1177 1\n",
      "1178 1\n",
      "1179 0\n",
      "1180 1\n",
      "1181 1\n",
      "1182 0\n",
      "1183 1\n",
      "1184 1\n",
      "1185 0\n",
      "1186 1\n",
      "1187 1\n",
      "1188 0\n",
      "1189 0\n",
      "1190 0\n",
      "1191 1\n",
      "1192 1\n",
      "1193 0\n",
      "1194 1\n",
      "1195 1\n",
      "1196 1\n",
      "1197 0\n",
      "1198 0\n",
      "1199 0\n",
      "1200 0\n",
      "1201 1\n",
      "1202 0\n",
      "1203 1\n",
      "1204 1\n",
      "1205 1\n",
      "1206 0\n",
      "1207 0\n",
      "1208 0\n",
      "1209 0\n",
      "1210 1\n",
      "1211 0\n",
      "1212 1\n",
      "1213 1\n",
      "1214 0\n",
      "1215 0\n",
      "1216 0\n",
      "1217 1\n",
      "1218 0\n",
      "1219 0\n",
      "1220 0\n",
      "1221 0\n",
      "1222 0\n",
      "1223 0\n",
      "1224 1\n",
      "1225 0\n",
      "1226 1\n",
      "1227 0\n",
      "1228 1\n",
      "1229 1\n",
      "1230 0\n",
      "1231 0\n",
      "1232 0\n",
      "1233 1\n",
      "1234 0\n",
      "1235 0\n",
      "1236 0\n",
      "1237 0\n",
      "1238 0\n",
      "1239 1\n",
      "1240 0\n",
      "1241 0\n",
      "1242 0\n",
      "1243 0\n",
      "1244 0\n",
      "1245 0\n",
      "1246 0\n",
      "1247 0\n",
      "1248 0\n",
      "1249 1\n",
      "1250 1\n",
      "1251 1\n",
      "1252 0\n",
      "1253 0\n",
      "1254 0\n",
      "1255 1\n",
      "1256 0\n",
      "1257 0\n",
      "1258 1\n",
      "1259 0\n",
      "1260 0\n",
      "1261 0\n",
      "1262 0\n",
      "1263 0\n",
      "1264 0\n",
      "1265 1\n",
      "1266 0\n",
      "1267 0\n",
      "1268 0\n",
      "1269 0\n",
      "1270 0\n",
      "1271 0\n",
      "1272 1\n",
      "1273 1\n",
      "1274 1\n",
      "1275 0\n",
      "1276 0\n",
      "1277 0\n",
      "1278 1\n",
      "1279 1\n",
      "1280 1\n",
      "1281 0\n",
      "1282 0\n",
      "1283 0\n",
      "1284 0\n",
      "1285 1\n",
      "1286 0\n",
      "1287 0\n",
      "1288 1\n",
      "1289 0\n",
      "1290 1\n",
      "1291 1\n",
      "1292 0\n",
      "1293 0\n",
      "1294 0\n",
      "1295 0\n",
      "1296 0\n",
      "1297 0\n",
      "1298 0\n",
      "1299 0\n",
      "1300 1\n",
      "1301 0\n",
      "1302 1\n",
      "1303 0\n",
      "1304 1\n",
      "1305 1\n",
      "1306 0\n",
      "1307 1\n",
      "1308 1\n",
      "1309 0\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "  train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "  print(\"train_dataset: {0}, validation_dataset.shape: {1}, test_dataset: {2}\".format(\n",
    "    len(train_dataset), len(validation_dataset), len(test_dataset)\n",
    "  ))\n",
    "  print(\"#\" * 50, 1)\n",
    "\n",
    "  for idx, sample in enumerate(train_dataset):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, sample['input'], sample['target']))\n",
    "\n",
    "  print(\"#\" * 50, 2)\n",
    "\n",
    "  # 데이터 로더 설정\n",
    "  train_data_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "  validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=16, shuffle=True)\n",
    "  test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset))\n",
    "\n",
    "  print(\"[TRAIN]\")\n",
    "  for idx, batch in enumerate(train_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"[VALIDATION]\")\n",
    "  for idx, batch in enumerate(validation_data_loader):\n",
    "    print(\"{0} - {1}: {2}\".format(idx, batch['input'].shape, batch['target'].shape))\n",
    "\n",
    "  print(\"#\" * 50, 3)\n",
    "\n",
    "    #테스트\n",
    "  test(test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1497a3f0-cd23-42f8-83e3-4e1c55b0c3aa",
   "metadata": {},
   "source": [
    "데이터셋 로드하고 전처리<br>\n",
    "각 데이터셋의 크기 및 내용을 확인<br>\n",
    "데이터 로더를 설정하여 데이터를 배치 단위로 처리<br>\n",
    "훈련 및 검증 데이터 로더에서 배치의 내용을 출력<br>\n",
    "테스트를 수행<br>\n",
    "출력을 확인해보면 테스트 데이터에 대한 예측된 생존 여부가 나타난것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70982b77-4c54-43d6-88cc-d4d560e30fc6",
   "metadata": {},
   "source": [
    "# **my_model_training.py**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f12970c0-e9a6-4906-b87b-f7af10de4597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이선우\\git\\link_dl !!!!!!!\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from datetime import datetime\n",
    "import wandb\n",
    "import argparse\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_PATH = str(Path.cwd().parent.parent)  # 현재 작업 디렉터리에서 상위 2단계로 이동\n",
    "print(BASE_PATH, \"!!!!!!!\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(BASE_PATH)  \n",
    "\n",
    "# Titanic 데이터셋 불러오기 및 전처리 함수\n",
    "from titanic_dataset import get_preprocessed_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a551770e-1b9b-4670-adf6-f504e5085cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    # 데이터셋 불러오기, 전처리\n",
    "    train_dataset, validation_dataset, test_dataset = get_preprocessed_dataset()\n",
    "\n",
    "    print(len(train_dataset), len(validation_dataset))\n",
    "\n",
    "    # 데이터 로더 생성\n",
    "    train_data_loader = DataLoader(dataset=train_dataset, batch_size=wandb.config.batch_size, shuffle=True)\n",
    "    validation_data_loader = DataLoader(dataset=validation_dataset, batch_size=len(validation_dataset))\n",
    "\n",
    "    return train_data_loader, validation_data_loader, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "49a1f9d8-48b1-4e6e-8df0-8715e1dedd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(nn.Module):\n",
    "    def __init__(self, n_input, n_output):\n",
    "        super().__init__()\n",
    "\n",
    "        # 타이타닉 데이터에 입출력 (11개 입력, 2개 출력 (생존/사망))\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(n_input, wandb.config.n_hidden_unit_list[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[0], wandb.config.n_hidden_unit_list[1]),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(wandb.config.n_hidden_unit_list[1], n_output),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0b8d68-b46e-427f-87a7-901d0f530c17",
   "metadata": {},
   "source": [
    "활성화 함수로 **ReLU** 사용 <br>해보니 제일 잘나옴"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81b24eb-f86c-4753-8935-d7d66510c5a3",
   "metadata": {},
   "source": [
    "ReLU : 입력이 양수일 때는 그대로 출력, 음수일 때는 0을 출력하는 활성화 함수, 음수에서 기울기가 0이 되어 죽은 뉴런 문제를 일으킬 수 있음.\n",
    "<br>ELU : 음수에서는 지수 함수로 변환하고, 양수에서는 그대로 출력하는 활성화 함수, 음수에서도 작은 값으로 변화시켜, 죽은 뉴런 문제를 완화 가능\n",
    "<br>Leaky ReLU : ReLU와 유사하지만, 음수 입력에 대해 작은 기울기를 허용하는 활성화 함수. 음수에서도 작은 기울기가 있어 죽은 뉴런 문제를 해결가능\n",
    "<br>PReLU : Leaky ReLU와 유사하지만, 음수 입력에 대한 기울기 α 값을 학습할 수 있는 활성화 함수.\n",
    "\n",
    "활성화 함수?? 비선형성을 도입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e355b8ac-e4bd-40d4-b254-ab87fd102b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_and_optimizer():\n",
    "    # 타이타닉 데이터셋 입력은 11개, 출력 2개 (생존 여부)\n",
    "    my_model = MyModel(n_input=11, n_output=2)\n",
    "    optimizer = optim.SGD(my_model.parameters(), lr=wandb.config.learning_rate)\n",
    "\n",
    "    return my_model, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b385f77-529b-497c-9181-8c583aa353fa",
   "metadata": {},
   "source": [
    "모델을 생성하며 최적화 알고리즘을 설정한다. (SGD(Stochastic Gradient Descent) 알고리즘 => 경사하강법을 통해 모델의 파라미터를 업데이트) <br>\n",
    "학습률(learning rate)을 wandb 설정에서 가져옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "c8b297a7-5963-489b-98a1-40395f7f10ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, optimizer, train_data_loader, validation_data_loader):\n",
    "    n_epochs = wandb.config.epochs # 학습할 에포크 수를 wandb 설정에서 가져옴\n",
    "    loss_fn = nn.CrossEntropyLoss()  # 이진 분류 문제를 위한 손실 함수\n",
    "    next_print_epoch = 100 # # 학습 정보를 출력 주기 100 에포크\n",
    "    patience = 20  # Early stopping 기준 patience 값\n",
    "    best_validation_loss = float('inf') # validation_loss 최소값 저장\n",
    "    early_stop_counter = 0 # validation_loss 개선되지 않은 에포크 횟수\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss_train = 0.0\n",
    "        num_trains = 0\n",
    "        for train_batch in train_data_loader:\n",
    "            input = train_batch['input']\n",
    "            target = train_batch['target']\n",
    "            output_train = model(input)\n",
    "            loss = loss_fn(output_train, target) # 예측 값과 실제 값 사이의 손실을 계산\n",
    "            loss_train += loss.item()\n",
    "            num_trains += 1\n",
    "\n",
    "            optimizer.zero_grad() # 이전 배치에서 계산된 기울기를 초기화\n",
    "            loss.backward() # 현재 배치에 대한 손실 값을 기준으로 기울기를 계산\n",
    "            optimizer.step() # 기울기를 사용해 모델의 파라미터를 업데이트\n",
    "\n",
    "        loss_validation = 0.0\n",
    "        num_validations = 0\n",
    "        with torch.no_grad(): #  검증 단계에서는 기울기 계산 X\n",
    "            for validation_batch in validation_data_loader: # 검증 데이터 불러옴\n",
    "                input = validation_batch['input']\n",
    "                target = validation_batch['target']\n",
    "                output_validation = model(input) #예측 값 계산\n",
    "                loss = loss_fn(output_validation, target) # 예측 값과 실제 답 사이 차이 계산\n",
    "                loss_validation += loss.item() #\n",
    "                num_validations += 1 # 배치 수\n",
    "\n",
    "        avg_validation_loss = loss_validation / num_validations\n",
    "\n",
    "\n",
    "        wandb.log({\n",
    "            \"Epoch\": epoch,\n",
    "            \"Training loss\": loss_train / num_trains,\n",
    "            \"Validation loss\": avg_validation_loss\n",
    "        })\n",
    "\n",
    "        if epoch >= next_print_epoch: # 에포크 결과 출력\n",
    "            print(\n",
    "                f\"Epoch {epoch}, \"\n",
    "                f\"Training loss {loss_train / num_trains:.4f}, \"\n",
    "                f\"Validation loss {avg_validation_loss:.4f}\"\n",
    "            )\n",
    "            next_print_epoch += 100\n",
    "\n",
    "            # 100 에포크마다 Early stopping 체크\n",
    "            if avg_validation_loss < best_validation_loss:\n",
    "                best_validation_loss = avg_validation_loss\n",
    "                early_stop_counter = 0\n",
    "            else:\n",
    "                early_stop_counter += 1\n",
    "\n",
    "            if early_stop_counter >= patience: # validation_loss가 patience 에포크 동안 개선되지 않으면 학습 중단\n",
    "                print(f\"{early_stop_counter}동안 epochs 개선 x.\")\n",
    "                print(f\"Early stopping at epoch {epoch}\")\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0870aec4-abba-44bf-986b-0565cd801555",
   "metadata": {},
   "source": [
    "손실 함수로 CrossEntropyLoss() 사용\n",
    "<br>**CrossEntropyLoss()** : 분류 문제를 다룰 때 사용되는 손실 함수 <br>모델이 예측한 클래스 확률과 실제 정답 레이블 간의 차이를 측정하는 손실 함수이며 이진 분류 문제에서 모델이 잘못된 예측을 했을 때 큰 손실 값을 반환함."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b65d83-7d33-4482-9a44-56e59fa380a3",
   "metadata": {},
   "source": [
    "훈련과정 중 어느 Epoch 시점에 테스트를 수행하여 submission.csv를 구성할 지 알기 위해 Early stopping 사용 <br>\n",
    "**Early stopping** : 모델 학습 과정에서 검증 성능이 더 이상 개선되지 않을 때 학습을 중단함 <br>\n",
    "에포크마다 검증 데이터에 대한 Validation Loss을 계산하고 검증 손실이 더 이상 감소하지 않고 일정 횟수 동안 개선되지 않으면 학습을 중단한다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "65852619-e49b-4bd1-8cd7-b1c12c25f775",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_submission_file(model, test_dataset, output_file=\"submission.csv\"):\n",
    "    # test 데이터 로더 생성\n",
    "    test_data_loader = DataLoader(dataset=test_dataset, batch_size=len(test_dataset), shuffle=False)\n",
    "\n",
    "    # 예측 수행\n",
    "    predictions = []\n",
    "    with torch.no_grad(): # 예측엔 기울기 계싼 x\n",
    "        for batch in test_data_loader: # 테스트 데이터셋에서 입력 데이터를 가져옴\n",
    "            input_data = batch['input']\n",
    "            output = model(input_data) # 모델에 입력 데이터를 전달해 예측 값 가져옴\n",
    "            predicted_labels = torch.argmax(output, dim=1) # 모델이 출력한 값에서 가장 큰 값을 가진 클래스를 선택\n",
    "            predictions.extend(predicted_labels.cpu().numpy())  # 예측 결과를 리스트에 저장\n",
    "\n",
    "\n",
    "    passenger_ids = list(range(892, 892 + len(test_dataset)))  # 테스트 데이터셋 PassengerId는 892부터 시작\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"PassengerId\": passenger_ids,\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Submission file saved to {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dcfbeac-56e8-42ed-8ace-4c657ebc3e66",
   "metadata": {},
   "source": [
    "예측을 수행하고 예측 결과에 대한 csv 파일을 저장한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "adbeba96-3115-42ea-bce7-c0cb92b92950",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(args):\n",
    "    current_time_str = datetime.now().astimezone().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "\n",
    "    config = {\n",
    "        'epochs': args.epochs,\n",
    "        'batch_size': args.batch_size,\n",
    "        'learning_rate': 1e-3,\n",
    "        'n_hidden_unit_list': [20, 20],\n",
    "    }\n",
    "\n",
    "    wandb.init(\n",
    "        mode=\"online\" if args.wandb else \"disabled\",\n",
    "        project=\"titanic_model_training\",\n",
    "        notes=\"Titanic dataset experiment\",\n",
    "        tags=[\"titanic\", \"classification\"],\n",
    "        name=current_time_str,\n",
    "        config=config\n",
    "    )\n",
    "    print(args)\n",
    "    print(wandb.config)\n",
    "\n",
    "    train_data_loader, validation_data_loader, test_dataset = get_data()\n",
    "\n",
    "    linear_model, optimizer = get_model_and_optimizer() # 모델 및 최적화 함수 생성\n",
    "\n",
    "    print(\"#\" * 50, 1)\n",
    "\n",
    "    training_loop(\n",
    "        model=linear_model,\n",
    "        optimizer=optimizer,\n",
    "        train_data_loader=train_data_loader,\n",
    "        validation_data_loader=validation_data_loader\n",
    "    )\n",
    "\n",
    "    # 테스트 데이터셋을 사용하여 결과를 저장\n",
    "    save_submission_file(model=linear_model, test_dataset=test_dataset, output_file=\"submission.csv\")\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea6c521-dbd2-492b-9479-5f69fbaf2ec4",
   "metadata": {},
   "source": [
    "모델 설정과 함께 Wandb를 통해 기록<br>\n",
    "Titanic 데이터셋을 훈련, 검증, 테스트용으로 나누어 로드<br>\n",
    "훈련 루프를 통해 모델을 학습<br>\n",
    "테스트 데이터를 사하여 예측 수행, submission.csv 파일 저장<br>\n",
    "Wandb 업로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f7679983-4df3-423d-8690-1c6957e3bf74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18923264a41b4b8fae0dc5d7b79616c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\이선우\\git\\link_dl\\_02_homeworks\\homework_2\\wandb\\run-20241025_232626-jlf2khcp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training/runs/jlf2khcp' target=\"_blank\">2024-10-25_23-26-26</a></strong> to <a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training' target=\"_blank\">https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training/runs/jlf2khcp' target=\"_blank\">https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training/runs/jlf2khcp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(wandb=True, batch_size=512, epochs=50000)\n",
      "{'epochs': 50000, 'batch_size': 512, 'learning_rate': 0.001, 'n_hidden_unit_list': [20, 20]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\이선우\\git\\link_dl\\_02_homeworks\\homework_2\\titanic_dataset.py:120: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"alone\"].fillna(0, inplace=True)\n",
      "C:\\Users\\이선우\\git\\link_dl\\_02_homeworks\\homework_2\\titanic_dataset.py:140: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  all_df[\"Embarked\"].fillna(\"missing\", inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "713 178\n",
      "################################################## 1\n",
      "Epoch 100, Training loss 0.5854, Validation loss 0.6714\n",
      "Epoch 200, Training loss 0.5896, Validation loss 0.6669\n",
      "Epoch 300, Training loss 0.5605, Validation loss 0.6640\n",
      "Epoch 400, Training loss 0.5734, Validation loss 0.6612\n",
      "Epoch 500, Training loss 0.5534, Validation loss 0.6604\n",
      "Epoch 600, Training loss 0.5653, Validation loss 0.6596\n",
      "Epoch 700, Training loss 0.5646, Validation loss 0.6566\n",
      "Epoch 800, Training loss 0.5699, Validation loss 0.6552\n",
      "Epoch 900, Training loss 0.5569, Validation loss 0.6537\n",
      "Epoch 1000, Training loss 0.5498, Validation loss 0.6536\n",
      "Epoch 1100, Training loss 0.5561, Validation loss 0.6534\n",
      "Epoch 1200, Training loss 0.5648, Validation loss 0.6519\n",
      "Epoch 1300, Training loss 0.5623, Validation loss 0.6499\n",
      "Epoch 1400, Training loss 0.5658, Validation loss 0.6483\n",
      "Epoch 1500, Training loss 0.5456, Validation loss 0.6482\n",
      "Epoch 1600, Training loss 0.5655, Validation loss 0.6475\n",
      "Epoch 1700, Training loss 0.5522, Validation loss 0.6463\n",
      "Epoch 1800, Training loss 0.5600, Validation loss 0.6446\n",
      "Epoch 1900, Training loss 0.5457, Validation loss 0.6450\n",
      "Epoch 2000, Training loss 0.5618, Validation loss 0.6410\n",
      "Epoch 2100, Training loss 0.5547, Validation loss 0.6417\n",
      "Epoch 2200, Training loss 0.5536, Validation loss 0.6403\n",
      "Epoch 2300, Training loss 0.5418, Validation loss 0.6386\n",
      "Epoch 2400, Training loss 0.5366, Validation loss 0.6385\n",
      "Epoch 2500, Training loss 0.5466, Validation loss 0.6383\n",
      "Epoch 2600, Training loss 0.5357, Validation loss 0.6380\n",
      "Epoch 2700, Training loss 0.5486, Validation loss 0.6350\n",
      "Epoch 2800, Training loss 0.5529, Validation loss 0.6346\n",
      "Epoch 2900, Training loss 0.5358, Validation loss 0.6342\n",
      "Epoch 3000, Training loss 0.5304, Validation loss 0.6323\n",
      "Epoch 3100, Training loss 0.5221, Validation loss 0.6319\n",
      "Epoch 3200, Training loss 0.5360, Validation loss 0.6295\n",
      "Epoch 3300, Training loss 0.5222, Validation loss 0.6291\n",
      "Epoch 3400, Training loss 0.5395, Validation loss 0.6283\n",
      "Epoch 3500, Training loss 0.5189, Validation loss 0.6262\n",
      "Epoch 3600, Training loss 0.5245, Validation loss 0.6262\n",
      "Epoch 3700, Training loss 0.5284, Validation loss 0.6239\n",
      "Epoch 3800, Training loss 0.5315, Validation loss 0.6238\n",
      "Epoch 3900, Training loss 0.5158, Validation loss 0.6224\n",
      "Epoch 4000, Training loss 0.5235, Validation loss 0.6207\n",
      "Epoch 4100, Training loss 0.5308, Validation loss 0.6196\n",
      "Epoch 4200, Training loss 0.5099, Validation loss 0.6198\n",
      "Epoch 4300, Training loss 0.5192, Validation loss 0.6191\n",
      "Epoch 4400, Training loss 0.5100, Validation loss 0.6159\n",
      "Epoch 4500, Training loss 0.5261, Validation loss 0.6148\n",
      "Epoch 4600, Training loss 0.5179, Validation loss 0.6138\n",
      "Epoch 4700, Training loss 0.5116, Validation loss 0.6114\n",
      "Epoch 4800, Training loss 0.5274, Validation loss 0.6084\n",
      "Epoch 4900, Training loss 0.5235, Validation loss 0.6084\n",
      "Epoch 5000, Training loss 0.5016, Validation loss 0.6063\n",
      "Epoch 5100, Training loss 0.5060, Validation loss 0.6055\n",
      "Epoch 5200, Training loss 0.4907, Validation loss 0.6027\n",
      "Epoch 5300, Training loss 0.5168, Validation loss 0.6023\n",
      "Epoch 5400, Training loss 0.5093, Validation loss 0.5966\n",
      "Epoch 5500, Training loss 0.5233, Validation loss 0.6006\n",
      "Epoch 5600, Training loss 0.5056, Validation loss 0.5958\n",
      "Epoch 5700, Training loss 0.5011, Validation loss 0.5948\n",
      "Epoch 5800, Training loss 0.4923, Validation loss 0.5935\n",
      "Epoch 5900, Training loss 0.4919, Validation loss 0.5942\n",
      "Epoch 6000, Training loss 0.4897, Validation loss 0.5870\n",
      "Epoch 6100, Training loss 0.4875, Validation loss 0.5868\n",
      "Epoch 6200, Training loss 0.4917, Validation loss 0.5857\n",
      "Epoch 6300, Training loss 0.4916, Validation loss 0.5817\n",
      "Epoch 6400, Training loss 0.4833, Validation loss 0.5794\n",
      "Epoch 6500, Training loss 0.4767, Validation loss 0.5772\n",
      "Epoch 6600, Training loss 0.4782, Validation loss 0.5761\n",
      "Epoch 6700, Training loss 0.4781, Validation loss 0.5730\n",
      "Epoch 6800, Training loss 0.4799, Validation loss 0.5711\n",
      "Epoch 6900, Training loss 0.4800, Validation loss 0.5706\n",
      "Epoch 7000, Training loss 0.4792, Validation loss 0.5644\n",
      "Epoch 7100, Training loss 0.4721, Validation loss 0.5633\n",
      "Epoch 7200, Training loss 0.4666, Validation loss 0.5596\n",
      "Epoch 7300, Training loss 0.4625, Validation loss 0.5637\n",
      "Epoch 7400, Training loss 0.4670, Validation loss 0.5554\n",
      "Epoch 7500, Training loss 0.4597, Validation loss 0.5560\n",
      "Epoch 7600, Training loss 0.4675, Validation loss 0.5508\n",
      "Epoch 7700, Training loss 0.4517, Validation loss 0.5480\n",
      "Epoch 7800, Training loss 0.4787, Validation loss 0.5458\n",
      "Epoch 7900, Training loss 0.4364, Validation loss 0.5500\n",
      "Epoch 8000, Training loss 0.4543, Validation loss 0.5433\n",
      "Epoch 8100, Training loss 0.4440, Validation loss 0.5447\n",
      "Epoch 8200, Training loss 0.4616, Validation loss 0.5371\n",
      "Epoch 8300, Training loss 0.4359, Validation loss 0.5363\n",
      "Epoch 8400, Training loss 0.4421, Validation loss 0.5334\n",
      "Epoch 8500, Training loss 0.4422, Validation loss 0.5333\n",
      "Epoch 8600, Training loss 0.4548, Validation loss 0.5275\n",
      "Epoch 8700, Training loss 0.4360, Validation loss 0.5277\n",
      "Epoch 8800, Training loss 0.4361, Validation loss 0.5237\n",
      "Epoch 8900, Training loss 0.4317, Validation loss 0.5220\n",
      "Epoch 9000, Training loss 0.4363, Validation loss 0.5193\n",
      "Epoch 9100, Training loss 0.4241, Validation loss 0.5188\n",
      "Epoch 9200, Training loss 0.4190, Validation loss 0.5161\n",
      "Epoch 9300, Training loss 0.4270, Validation loss 0.5187\n",
      "Epoch 9400, Training loss 0.4212, Validation loss 0.5118\n",
      "Epoch 9500, Training loss 0.4194, Validation loss 0.5342\n",
      "Epoch 9600, Training loss 0.4451, Validation loss 0.6185\n",
      "Epoch 9700, Training loss 0.4214, Validation loss 0.5082\n",
      "Epoch 9800, Training loss 0.4309, Validation loss 0.5141\n",
      "Epoch 9900, Training loss 0.4358, Validation loss 0.5106\n",
      "Epoch 10000, Training loss 0.4444, Validation loss 0.5040\n",
      "Epoch 10100, Training loss 0.4068, Validation loss 0.5015\n",
      "Epoch 10200, Training loss 0.3995, Validation loss 0.5162\n",
      "Epoch 10300, Training loss 0.3915, Validation loss 0.5079\n",
      "Epoch 10400, Training loss 0.4221, Validation loss 0.5003\n",
      "Epoch 10500, Training loss 0.4166, Validation loss 0.4939\n",
      "Epoch 10600, Training loss 0.3968, Validation loss 0.4929\n",
      "Epoch 10700, Training loss 0.3980, Validation loss 0.5029\n",
      "Epoch 10800, Training loss 0.4019, Validation loss 0.5082\n",
      "Epoch 10900, Training loss 0.4090, Validation loss 0.4935\n",
      "Epoch 11000, Training loss 0.4103, Validation loss 0.5488\n",
      "Epoch 11100, Training loss 0.4295, Validation loss 0.4880\n",
      "Epoch 11200, Training loss 0.4134, Validation loss 0.5003\n",
      "Epoch 11300, Training loss 0.4132, Validation loss 0.4873\n",
      "Epoch 11400, Training loss 0.3935, Validation loss 0.4889\n",
      "Epoch 11500, Training loss 0.3831, Validation loss 0.4988\n",
      "Epoch 11600, Training loss 0.3980, Validation loss 0.4936\n",
      "Epoch 11700, Training loss 0.4071, Validation loss 0.4890\n",
      "Epoch 11800, Training loss 0.4220, Validation loss 0.4802\n",
      "Epoch 11900, Training loss 0.3999, Validation loss 0.5382\n",
      "Epoch 12000, Training loss 0.3846, Validation loss 0.5079\n",
      "Epoch 12100, Training loss 0.4268, Validation loss 0.5122\n",
      "Epoch 12200, Training loss 0.4136, Validation loss 0.4842\n",
      "Epoch 12300, Training loss 0.3932, Validation loss 0.4791\n",
      "Epoch 12400, Training loss 0.3809, Validation loss 0.4873\n",
      "Epoch 12500, Training loss 0.3942, Validation loss 0.4953\n",
      "Epoch 12600, Training loss 0.4120, Validation loss 0.4797\n",
      "Epoch 12700, Training loss 0.3974, Validation loss 0.4866\n",
      "Epoch 12800, Training loss 0.4063, Validation loss 0.5669\n",
      "Epoch 12900, Training loss 0.3791, Validation loss 0.4758\n",
      "Epoch 13000, Training loss 0.3767, Validation loss 0.4791\n",
      "Epoch 13100, Training loss 0.4015, Validation loss 0.4805\n",
      "Epoch 13200, Training loss 0.4591, Validation loss 0.4952\n",
      "Epoch 13300, Training loss 0.4244, Validation loss 0.4795\n",
      "Epoch 13400, Training loss 0.3974, Validation loss 0.4831\n",
      "Epoch 13500, Training loss 0.3821, Validation loss 0.4789\n",
      "Epoch 13600, Training loss 0.3989, Validation loss 0.4768\n",
      "Epoch 13700, Training loss 0.4007, Validation loss 0.4828\n",
      "Epoch 13800, Training loss 0.4087, Validation loss 0.4771\n",
      "Epoch 13900, Training loss 0.4405, Validation loss 0.5756\n",
      "Epoch 14000, Training loss 0.5188, Validation loss 0.4912\n",
      "Epoch 14100, Training loss 0.3959, Validation loss 0.4777\n",
      "Epoch 14200, Training loss 0.3872, Validation loss 0.4716\n",
      "Epoch 14300, Training loss 0.4096, Validation loss 0.5566\n",
      "Epoch 14400, Training loss 0.3998, Validation loss 0.6059\n",
      "Epoch 14500, Training loss 0.3814, Validation loss 0.4708\n",
      "Epoch 14600, Training loss 0.4771, Validation loss 0.5152\n",
      "Epoch 14700, Training loss 0.3998, Validation loss 0.4737\n",
      "Epoch 14800, Training loss 0.3790, Validation loss 0.4985\n",
      "Epoch 14900, Training loss 0.3918, Validation loss 0.4993\n",
      "Epoch 15000, Training loss 0.3954, Validation loss 0.5536\n",
      "Epoch 15100, Training loss 0.3697, Validation loss 0.4734\n",
      "Epoch 15200, Training loss 0.3808, Validation loss 0.4792\n",
      "Epoch 15300, Training loss 0.3991, Validation loss 0.4770\n",
      "Epoch 15400, Training loss 0.4318, Validation loss 0.6187\n",
      "Epoch 15500, Training loss 0.4676, Validation loss 0.5568\n",
      "Epoch 15600, Training loss 0.4006, Validation loss 0.4884\n",
      "Epoch 15700, Training loss 0.3924, Validation loss 0.4742\n",
      "Epoch 15800, Training loss 0.3883, Validation loss 0.4668\n",
      "Epoch 15900, Training loss 0.4023, Validation loss 0.4732\n",
      "Epoch 16000, Training loss 0.3754, Validation loss 0.4735\n",
      "Epoch 16100, Training loss 0.4387, Validation loss 0.5146\n",
      "Epoch 16200, Training loss 0.3767, Validation loss 0.4726\n",
      "Epoch 16300, Training loss 0.3894, Validation loss 0.5160\n",
      "Epoch 16400, Training loss 0.4133, Validation loss 0.5497\n",
      "Epoch 16500, Training loss 0.3913, Validation loss 0.4820\n",
      "Epoch 16600, Training loss 0.4075, Validation loss 0.4867\n",
      "Epoch 16700, Training loss 0.4500, Validation loss 0.4966\n",
      "Epoch 16800, Training loss 0.4209, Validation loss 0.5035\n",
      "Epoch 16900, Training loss 0.3540, Validation loss 0.5142\n",
      "Epoch 17000, Training loss 0.3757, Validation loss 0.4876\n",
      "Epoch 17100, Training loss 0.3895, Validation loss 0.4955\n",
      "Epoch 17200, Training loss 0.4853, Validation loss 0.5056\n",
      "Epoch 17300, Training loss 0.3784, Validation loss 0.4691\n",
      "Epoch 17400, Training loss 0.3899, Validation loss 0.4747\n",
      "Epoch 17500, Training loss 0.3905, Validation loss 0.5404\n",
      "Epoch 17600, Training loss 0.3602, Validation loss 0.4991\n",
      "Epoch 17700, Training loss 0.3858, Validation loss 0.4694\n",
      "Epoch 17800, Training loss 0.3584, Validation loss 0.4863\n",
      "20동안 epochs 개선 x.\n",
      "Early stopping at epoch 17800\n",
      "Submission file saved to submission.csv\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='0.017 MB of 0.017 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇██</td></tr><tr><td>Training loss</td><td>██▇▇▇▇▇▇▆▆▆▆▆▆▆▆▅▆▄▄▃▃▃▃▂▄▂▂▂▁▅▂▁▃▂▂▂▂▁▁</td></tr><tr><td>Validation loss</td><td>████▇▇▇▇▇▇▇▇▇▇▇▆▆▅▄▃▃▂▂▃▂▂▁▁▃▄▁▁▁▁▂▃▁▂▃▃</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Epoch</td><td>17800</td></tr><tr><td>Training loss</td><td>0.35836</td></tr><tr><td>Validation loss</td><td>0.48629</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">2024-10-25_23-26-26</strong> at: <a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training/runs/jlf2khcp' target=\"_blank\">https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training/runs/jlf2khcp</a><br/> View project at: <a href='https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training' target=\"_blank\">https://wandb.ai/tjsdn052-korea-university-of-technology-and-education5144/titanic_model_training</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20241025_232626-jlf2khcp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://docs.wandb.ai/guides/track/config\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # Wandb 설정\n",
    "    parser.add_argument(\n",
    "        \"--wandb\", action=argparse.BooleanOptionalAction, default=True, help=\"True or False\"\n",
    "    )\n",
    "\n",
    "    # 배치 크기 설정\n",
    "    parser.add_argument(\n",
    "        \"-b\", \"--batch_size\", type=int, default=512, help=\"Batch size (int, default: 512)\"\n",
    "    )\n",
    "\n",
    "    # 에포크 수 설정\n",
    "    parser.add_argument(\n",
    "        \"-e\", \"--epochs\", type=int, default=5_0000, help=\"Number of training epochs (int, default: 50000)\"\n",
    "    )\n",
    "\n",
    "    args, unknown = parser.parse_known_args()\n",
    "\n",
    "    # main 함수 실행\n",
    "    main(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d13aac3-1aea-417d-844e-aff07964463e",
   "metadata": {},
   "source": [
    "# **Kaggle 등수**"
   ]
  },
  {
   "attachments": {
    "196ffa1d-6fde-40c2-912c-3a99a9f35f71.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "864c6878-f051-435e-b250-3081d1da8ae7",
   "metadata": {},
   "source": [
    "![le.png](attachment:196ffa1d-6fde-40c2-912c-3a99a9f35f71.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "437134fe-a723-473e-8ce7-0665f9fedcbd",
   "metadata": {},
   "source": [
    "## **숙제후기**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dff2bae-ac73-4630-8ba3-8dd329622374",
   "metadata": {},
   "source": [
    "이번 과제를 수행하면서 수집된 데이터가 어떠한 방식으로 전처리 되고 모델에 학습되고 예측을 수행하는지 그 흐름을 알게되었다. 최적의 지점에서 중단하고 csv 파일을 생성하기 위해 early stoping을 이용했는데 너무 초반에 멈춰서 그런지 처음 캐글에 해당 모델에서 예측된 csv 파일을 업로드했을땐 0.67xxx 정도의 점수가 나왔다. 좀 길게 가져가기 위해 100단위로 끊고 거기서 또 10회 또는 20회 검증 손실이 개선되지 않아야 멈추는것으로 변경했더니 0.76xxx까진 올랐다. 또한 수행하면서 좀 편차가 크게 나왔는데 이게 정상적인건지는 의문이다. 코드를 건든 부분은 좀 적지만 그래도 어떠한 데이터를 가지고 모델을 학습시키고 예측을 수행하며 교재, 코드로만 보는것보다 더 깊게 알게된것같다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d23a4f-8117-40b8-a49a-d8ef09d5c34e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
